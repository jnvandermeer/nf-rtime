{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playback an existing recording\n",
    "\n",
    "If you don't have an EEG system currently acquiring data, you can still do testing of stimuli by playing back an existing recording. We have such a recording in example-dataset.set, whose contents are described in [2_1_SignalAcquisition.ipynb](2_1_SignalAcquisition.ipynb).\n",
    "\n",
    "What we do in this notebook is to load in that dataset using [MNE Python](https://mne.tools/stable/index.html), examine some aspects, and then use pyLSL to create an output stream as described [here](https://github.com/sccn/labstreaminglayer/wiki/ExampleCode) where we push in that data just as if it's acquired at this very moment. Then in [2_3_SignalPlaybackCheck.ipynb](2_3_SignalPlaybackCheck.ipynb) we will examine that data.\n",
    "\n",
    "First we grab MNE Python:\n",
    "```python\n",
    "import mne\n",
    "```\n",
    "\n",
    "and the dataset is here:\n",
    "```python\n",
    "data_file = '/home/rt/nf/example-data.set'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "data_file = '/home/rt/nf/example-data.set'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNE Python comes with extensive tutorials how to import data and do all kinds of analyses, including spatial and temporal filtering and visualization of data; some of these things we will definitely use later on. The Python Neurofeedback toolbox made by the Russians [NFB Lab](https://github.com/nikolaims/nfb) also uses a lot of MNE's functionalities.\n",
    "\n",
    "For now we just use the functionality to read in EEGLab data (which in our case is just a matlab.mat file, which we could also have imported with python's scipy module. But MNE makes things a little bit easier.\n",
    "\n",
    "```python\n",
    "raw = mne.io.read_raw_eeglab(data_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ea90f48313e8>:1: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(data_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawEEGLAB  |  example-data.set, n_channels x n_times : 13 x 633858 (633.9 sec), ~62.9 MB, data loaded>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ea90f48313e8>:1: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(data_file)\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_eeglab(data_file)\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you might see some warnings about boundary, and reloading not being supported - but you also should see that there are 13 channels and 63358 datapoints, and how many seconds there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__contains__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_annotations', '_cals', '_check_bad_segment', '_comp', '_data', '_dtype', '_dtype_', '_filenames', '_first_samps', '_first_time', '_get_buffer_size', '_get_channel_positions', '_init_kwargs', '_last_samps', '_last_time', '_orig_units', '_parse_get_set_params', '_pick_drop_channels', '_preload_data', '_projector', '_projectors', '_raw_extras', '_raw_lengths', '_read_comp_grade', '_read_segment', '_read_segment_file', '_set_channel_positions', '_set_dig_montage_in_init', '_size', '_times', '_update_times', 'add_channels', 'add_events', 'add_proj', 'annotations', 'anonymize', 'append', 'apply_function', 'apply_gradient_compensation', 'apply_hilbert', 'apply_proj', 'buffer_size_sec', 'ch_names', 'close', 'compensation_grade', 'copy', 'crop', 'del_proj', 'drop_channels', 'estimate_rank', 'filenames', 'filter', 'first_samp', 'get_data', 'info', 'interpolate_bads', 'last_samp', 'load_bad_channels', 'load_data', 'n_times', 'notch_filter', 'orig_format', 'pick', 'pick_channels', 'pick_types', 'plot', 'plot_projs_topomap', 'plot_psd', 'plot_psd_topo', 'plot_sensors', 'preload', 'proj', 'rename_channels', 'reorder_channels', 'resample', 'save', 'savgol_filter', 'set_annotations', 'set_channel_types', 'set_eeg_reference', 'set_montage', 'time_as_index', 'times', 'to_data_frame', 'verbose']\n"
     ]
    }
   ],
   "source": [
    "print(dir(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab sample rate:\n",
    "sfreq = raw.info['sfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the number of channels\n",
    "nchans = len(raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the data as a numpy array\n",
    "data = raw.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays are python's way to emulate how Matlab organizes matrices. See [here](https://numpy.org/devdocs/user/quickstart.html) for documentation on Numpy, some of the methods we're going to use below (and throughout the NF work)\n",
    "\n",
    "numpy is usually imported into python (like matlab's addpath) like so:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "we don't actually need to use np to do anything, since data is already a numpy array. MNE uses numpy inherently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 633858)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have sfreq, nchans, and data as an np array - we will now use code found in the [Example Code Guide](https://github.com/sccn/labstreaminglayer/wiki/ExampleCode), specifically that for [python](https://github.com/labstreaminglayer/liblsl-Python/blob/master/pylsl/examples/SendData.py), to send data sample-by-sample.\n",
    "\n",
    "The code you can find is:\n",
    "\n",
    "```python\n",
    "\"\"\"Example program to demonstrate how to send a multi-channel time series to\n",
    "LSL.\"\"\"\n",
    "\n",
    "import time\n",
    "from random import random as rand\n",
    "\n",
    "from pylsl import StreamInfo, StreamOutlet\n",
    "\n",
    "# first create a new stream info (here we set the name to BioSemi,\n",
    "# the content-type to EEG, 8 channels, 100 Hz, and float-valued data) The\n",
    "# last value would be the serial number of the device or some other more or\n",
    "# less locally unique identifier for the stream as far as available (you\n",
    "# could also omit it but interrupted connections wouldn't auto-recover)\n",
    "info = StreamInfo('BioSemi', 'EEG', 8, 100, 'float32', 'myuid34234')\n",
    "\n",
    "# next make an outlet\n",
    "outlet = StreamOutlet(info)\n",
    "\n",
    "print(\"now sending data...\")\n",
    "while True:\n",
    "    # make a new random 8-channel sample; this is converted into a\n",
    "    # pylsl.vectorf (the data type that is expected by push_sample)\n",
    "    mysample = [rand(), rand(), rand(), rand(), rand(), rand(), rand(), rand()]\n",
    "    # now send it and wait for a bit\n",
    "    outlet.push_sample(mysample)\n",
    "    time.sleep(0.01)\n",
    "```\n",
    "\n",
    "We will do some modifications to emulate our sampling rate (1000 Hz) in a slightly better way, since the push_sample might also take some time itself and cause some accumulation of sampling error over time for longer recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create info for our purposes:\n",
    "info = pylsl.StreamInfo('Playback', 'EEG', nchans, sfreq, 'float32', 'someidentifier123')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also, we'd need to provide LSL with some information regarding the channels as shown [here](https://github.com/labstreaminglayer/liblsl-Python/blob/master/pylsl/examples/HandleMetadata.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chns = info.desc().append_child(\"channels\")\n",
    "for label in raw.ch_names:\n",
    "    ch = chns.append_child(\"channel\")\n",
    "    ch.append_child_value(\"label\", label)\n",
    "    ch.append_child_value(\"unit\", \"microvolts\")\n",
    "    ch.append_child_value(\"type\", \"EEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an outlet; this is basically the keymaster that creates/destroys tunnels (through which data flows) with incoming petitioners (clients)\n",
    "\n",
    "Currently, no data is (yet!) flowing, but if you push data in it, it will still accumulate, like in a reservoir or a buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlet = pylsl.StreamOutlet(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to transpose data, and then we can for-loop over it like so (extensively verbose):\n",
    "\n",
    "time_to_send_new_data_point = time.time()\n",
    "time_to_wait_between_sending_data_points = 1/sfreq\n",
    "\n",
    "for data_point in data.T:\n",
    "    \n",
    "    time_to_send_new_data_point += time_to_wait_between_sending_data_points\n",
    "    while time.time() < time_to_send_new_data_point:\n",
    "        time.sleep(0.00001)\n",
    "    \n",
    "    outlet.push_sample(data_point)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python interpreter (behind this notebook) will 'hang' because it is executing the block of code and will continue to do so until all data has been sent out.\n",
    "So now we have the stream running - you can go to [2_3_SignalPlaybackCheck.ipynb](2_3_SignalPlaybackCheck.ipynb) to take a look at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
