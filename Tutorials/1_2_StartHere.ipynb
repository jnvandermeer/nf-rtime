{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to BCI / NF\n",
    "\n",
    "\n",
    "The main goal of BCI is to use real-time EEG (or other) data to do something interesting immediately with your experiment. It can be:\n",
    " - Display the signal back to the participant as something to train (with hopeful benefits later on)\n",
    " - Figure out what people are thingking about between two options, i.e. decode\n",
    " - Track e.g. an EEG Vigilance marker and use it to intervene, i.e. wake the participant up\n",
    " - Track EEG data quality in real-time so you know when things start to look dire - and you can intervene\n",
    " - Adaptive Paradigms: Change the timing of your stimuli, so that they occur when the brain is in the correct state (as determined by calibration measurements)\n",
    " \n",
    "Methodologically, what is needed are always:\n",
    " - A way to setup / collect incoming EEG data in real-time - into a stream\n",
    " - A way to analyze data in real-time (which brings its own caveats and issues)\n",
    " - A way to communicate things to the stimulus (whatever that is)\n",
    " \n",
    " \n",
    "In terms of experimental paradigm or measuremnts, there is always (or almost always) \n",
    " - the *calibration* measurement \n",
    "   - In principle, this is the exact same situation as a normal EEG experiment. You might obtain some information about \n",
    "     - Alha Power Levels (eyes open/closed)\n",
    "     - Eyeblinks (how they look like)\n",
    "     - Muscle Artifacts\n",
    "     - Which channels are simply Bad\n",
    "     - A marker of EEG activity which is linked to the stuff you're trying to do in the next measuremment\n",
    "    - this is NOT a real-time experiment, (although you do access the real-tiem data stream) \n",
    "    - Is it usually a short(er) session just to get in some data in the same setting/setup as the real-time experiment\n",
    "    - and you analyze immideately after you got the data, taking the parameters with you to the next (real) experiment\n",
    " - the *real* experiment\n",
    "   - Here there are two main things that are 'extra'\n",
    "     - the real-time analysis\n",
    "     - the communication with your stimuli\n",
    "\n",
    "\n",
    "\n",
    "Setting up the real-time data stream and visualizing the data is the very first step, so we begin with that.\n",
    "\n",
    "The following notebooks explain things in a bit more detail(s):\n",
    "1. [Real-Time Signal Acquisition](2_1_SignalAcquisition.ipynb)\n",
    "2. [Real-Time Strategy (and Approach)](3_1_Strategy.ipynb)\n",
    "3. [Real-Time Signal Analysis](4_1_SignalAnalysis.ipynb)\n",
    "4. [Real-Time Feedback](5_1_Feedback.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "So by now you should have the rt set up on your own (linux or windows) computer, or use the virtual machine (where it is already set up), you ran the `conda activate rt`, navigated to `~/nf`, and started `juypter lab`. There, you navigated towards /nf-rtime/Tutorials and found this page. Or, you double-clicked the desktop shortcut!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additionals: On Strategies (and what you want with it)\n",
    "\n",
    "Then, the next thing depends basically on what you try do to (as explained in the first list). Basically, you can do anything you want, given limitations imposed by real-time analysis and computation speed.\n",
    "\n",
    "For example, you might wish to do a Neurofeedback Training. But, you do not wish to do feedback on eyeblinks, so you wish to remove them (immedieately), and then, you wish also extract the average power in a certain frequency band before giving this as a feedback to the participant who is supposed to train that signal. Additionally. you also do not wish to do training on muscle artifacts, so you need to detect that too, and figure out what to do with it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additionals: On Filtering\n",
    "\n",
    "For example, doing a real-time eyeblink removal is possible and which will be the part I will demonstrate here. We can do it because we have 16 channels to use -- by using a spatial filter, we can just get a spatial filter for 'eyeblink removal' and apply it to each data point coming in. Another example is a 'Common Spatial Pattern' for Alpha Power activity. Here also, one could apply the spatial pattern as the data is coming in.\n",
    "\n",
    "You could also extract the power in a certain frequency band - this is a temporaal filter, since you need a couple of timepoints in order to calculate an output. Usually, application of these temporal filters both introduce a time-delay in the output signal, as well as needing to remember past time points to work properly.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
