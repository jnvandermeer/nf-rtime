{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nftools import guis\n",
    "import pylsl\n",
    "import time\n",
    "import numpy as np\n",
    "import mne, re\n",
    "\n",
    "%matplotlib qt  \n",
    "import warnings; warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the EEG Cap\n",
    "\n",
    "- fix the EEG Cap\n",
    "- run the `python raw_eo_data --stream`, followed by `/start`\n",
    "- (re)-start the Cap or USB if it doesn't work, followed by commands above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = openbci_eeg\n",
      "sampling_freq = 125\n",
      "channel_count = 16\n",
      "channel_format = 1\n"
     ]
    }
   ],
   "source": [
    "# make the connection to the EEG Net (EEG Data)\n",
    "data_stream=pylsl.resolve_byprop(\"name\", \"openbci_eeg\", timeout=5.0)\n",
    "if data_stream:\n",
    "    data_inlet=pylsl.stream_inlet(data_stream[0])\n",
    "    stream_info = data_inlet.info()\n",
    "    stream_Fs = stream_info.nominal_srate()\n",
    "    stream_xml = stream_info.desc()\n",
    "    chans_xml = stream_xml.child(\"channels\")\n",
    "    chan_xml_list = []\n",
    "    ch = chans_xml.child(\"channel\")\n",
    "    while ch.name() == \"channel\":\n",
    "        chan_xml_list.append(ch)\n",
    "        ch = ch.next_sibling(\"channel\")\n",
    "    channel_names = [ch_xml.child_value(\"label\") for ch_xml in chan_xml_list]\n",
    "    data_inlet_dt = data_inlet.time_correction(timeout=5.0)\n",
    "    sampling_freq = data_stream[0].nominal_srate()\n",
    "    print('name = %s' % data_stream[0].name())\n",
    "    print('sampling_freq = %d' % sampling_freq)\n",
    "    print('channel_count = %d' % data_stream[0].channel_count())\n",
    "    print('channel_format = %d' % data_stream[0].channel_format())\n",
    "else:\n",
    "    raise Exception('No Data Stream Found - Is your EEG Cap running?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get (~ 2-3 minutes) of Eyes Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=16, n_times=2089\n",
      "    Range : 0 ... 2088 =      0.000 ...    16.704 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# clear EEG Data buffer\n",
    "while data_inlet.samples_available(): data_inlet.pull_chunk() \n",
    "\n",
    "# collect some data    \n",
    "np_eo = []\n",
    "w=guis.AcquireData(sampling_freq, channel_names)\n",
    "while w.RUNLOOP:\n",
    "    chunk_data, chunk_times = data_inlet.pull_chunk() # grab from LSL\n",
    "    if chunk_data:  # if there is any data\n",
    "        np_eo.append(chunk_data) # add to our list\n",
    "        w.update(chunk_data) # update the GUI window\n",
    "\n",
    "# and we make the MNE data file from it        \n",
    "raw_eo = mne.io.RawArray(np.concatenate(np_eo).T,\n",
    "                        mne.create_info(channel_names, \n",
    "                                    sampling_freq, \n",
    "                                    'eeg', \n",
    "                                    None)\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Bad Channels and Bad Time Intervals\n",
    "- Use the MNE Interface to click channels (those are bad)\n",
    "- Use also the MNE Interface ('a' button) to mark/drag\n",
    "bad segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "raw_eo.plot(scalings='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C3', 'T5', 'T6', 'C4']\n",
      "7.7, 8.3\n",
      "14, 16\n",
      "channels to remove: [2, 3, 4, 5]\n",
      "channel mask: [True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, True]\n",
      "number of samples to remove: 305\n",
      "raw original shape: 16, 2089\n",
      "np new shape: 1784, 12\n",
      "apply filter: 3 to 45\n",
      "Dropped 93 outliers\n",
      "Creating RawArray with float64 data, n_channels=12, n_times=1691\n",
      "    Range : 0 ... 1690 =      0.000 ...    13.520 secs\n",
      "Ready.\n",
      "Fitting ICA to data using 12 channels (please be patient, this may take a while)\n",
      "Inferring max_pca_components from picks\n",
      "Using all PCA components: 12\n",
      "Computing Extended Infomax ICA\n",
      "Fitting ICA took 1.2s.\n",
      "ICA/CSP time elapsed = 1.212555170059204s\n",
      "Table drawing time elapsed = 3.0800065994262695s\n",
      "Created an ICA Spatial Filter\n",
      "<pynfb.signal_processing.filters.SpatialRejection object at 0x7f16019fbcc0>\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "# extracting the ch names and time information\n",
    "bad_channels = raw_eo.info['bads']\n",
    "bad_segments = [(a['onset'], a['duration']) for a in raw_eo.annotations if re.search('BAD', a['description'])]\n",
    "print(bad_channels)\n",
    "for s in bad_segments: print('%.2g, %.2g' % (s[0], sum(s)))\n",
    "\n",
    "# convert to ch mask; and samples to keep/remove\n",
    "bad_channel_indices = [i for i, ch in enumerate(raw_eo.info['ch_names']) \n",
    "                    if ch in bad_channels]\n",
    "bad_channel_mask = [ch not in bad_channels for ch in channel_names]\n",
    "\n",
    "[range(int(b * sampling_freq), int((b+d) * sampling_freq)) for b, d in bad_segments]\n",
    "\n",
    "if bad_segments:\n",
    "    bad_segment_samples = np.concatenate([range(int(b * sampling_freq), int((b+d) * sampling_freq)) for b, d in bad_segments])\n",
    "else:\n",
    "    bad_segment_samples=[]\n",
    "\n",
    "print('channels to remove: %s' % bad_channel_indices)\n",
    "print('channel mask: ' + repr(bad_channel_mask))\n",
    "print('number of samples to remove: %s' % len(bad_segment_samples))\n",
    "\n",
    "# remove the bad channels and bad samples, make new data matrices:\n",
    "np_eo_forica = raw_eo.copy().get_data().T\n",
    "\n",
    "np_eo_forica = np.delete(np_eo_forica, bad_segment_samples, axis=0)\n",
    "np_eo_forica = np.delete(np_eo_forica, bad_channel_indices, axis=1)\n",
    "\n",
    "print('raw original shape: %d, %d' % raw_eo.get_data().shape)\n",
    "print('np new shape: %d, %d' % np_eo_forica.shape)\n",
    "\n",
    "# # inspect the new data matrix in the viewer\n",
    "# raw_eo_forica = mne.io.RawArray(np_eo_forica.T,\n",
    "#                         mne.create_info([n for n in channel_names if n not in bad_channels], \n",
    "#                                     sampling_freq, \n",
    "#                                     'eeg', \n",
    "#                                     None)\n",
    "#                        )\n",
    "\n",
    "# raw_eo_forica.plot(scalings='auto');\n",
    "\n",
    "from pynfb.protocols.ssd.topomap_selector_ica import ICADialog\n",
    "\n",
    "ica_rejection, _, _, ica_unmixing_matrix, _, _ = ICADialog.get_rejection(\n",
    "    np_eo_forica, \n",
    "    [n for n in channel_names if n not in bad_channels], \n",
    "    sampling_freq,\n",
    "    decomposition=None\n",
    ")\n",
    "\n",
    "ica_rejection = ica_rejection.expand_by_mask(bad_channel_mask)\n",
    "\n",
    "print('Created an ICA Spatial Filter')\n",
    "print(ica_rejection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up the Stimulus on Computer\n",
    "- connect via WiFi\n",
    "    - ip address = 10.42.0.1\n",
    "    - host = stim-pc\n",
    "    - password = PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from callpyff import bcinetwork, bcixml\n",
    "bcinet = bcinetwork.BciNetwork('10.42.0.1', bcinetwork.FC_PORT, bcinetwork.GUI_PORT, 'bcixml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TestD2', 'MovingRhomb', 'EOEC', 'LibetClock', 'BrainWaveTraining_II', 'TobiQLAdapter', 'VisualOddballVE', 'EyetrackerFeedback', 'HexoSpeller', 'P300_Rectangle', 'ERPHex', 'BrainWaveTraining', 'StopVigilanceTask', 'FeedbackCursorArrow', 'TrivialPong', 'CheckerboardVEP', 'HexoSpellerVE', 'BoringClock', 'nback_verbal', 'Lesson01', 'BrainPong', 'CakeSpellerVE', 'MovingRhombGL', 'RestingState', 'NFBasicThermometer', 'RSVPSpeller', 'EEGfMRILocalizer', 'MultiVisualOddball', 'Lesson01b', 'GoalKeeper', 'CenterSpellerVE', 'Oddball', 'EyetrackerRawdata', 'StroopFeedback', 'ERPMatrix', 'Lesson04', 'Lesson05', 'Lesson06', 'VisualOddball', 'Lesson02', 'Lesson03']\n"
     ]
    }
   ],
   "source": [
    "feedbacks = bcinet.getAvailableFeedbacks()\n",
    "print(feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet.send_init('BrainWaveTraining_II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet.send_signal(bcixml.BciSignal({'EX_TESTNFNOISE': False},None, bcixml.INTERACTION_SIGNAL))\n",
    "bcinet.send_signal(bcixml.BciSignal({'MONITOR_PIXWIDTH': 1366},None, bcixml.INTERACTION_SIGNAL))\n",
    "bcinet.send_signal(bcixml.BciSignal({'MONITOR_PIXHEIGHT': 768},None, bcixml.INTERACTION_SIGNAL))\n",
    "bcinet.send_signal(bcixml.BciSignal({'MONITOR_FULLSCR': True},None, bcixml.INTERACTION_SIGNAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr: 1.00, dur: 0.20\n",
      "bcinet is passed on\n",
      "thr: 10.00, dur: 0.15\n",
      "bcinet is passed on\n"
     ]
    }
   ],
   "source": [
    "# parameters to convert the filtered EEG signal to the stimulus\n",
    "from nftools.nftools import signaltracking\n",
    "track_for_eeg_stimuli = signaltracking.sending_to_nfstim(\n",
    "    thr=1.0, \n",
    "    dur=0.20, \n",
    "    feedback_type='eeg', \n",
    "    max4audio=1.2, \n",
    "    bcinet=bcinet, \n",
    "    st_scaling=10\n",
    ")\n",
    "\n",
    "# parameters to convert the filtered EMG signal to the stimulus\n",
    "track_for_emg_stimuli = signaltracking.sending_to_nfstim(\n",
    "    thr=10, \n",
    "    dur=0.15, \n",
    "    feedback_type='emg', \n",
    "    bcinet=bcinet, \n",
    "    st_scaling=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Real-Time EEG Signal Analysis during NF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynfb.signal_processing.filters import (FilterSequence, \n",
    "                                             CFIRBandEnvelopeDetector, \n",
    "                                             ExponentialSmoother,\n",
    "                                             SpatialFilter,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Filter Sequence for NF\n",
    "\n",
    "# Which channel do we select for the EEG?\n",
    "rt_eeg_channels = ['C3']\n",
    "rt_eeg_channels_mask = np.where([ch in rt_eeg_channels for ch in channel_names], 1, 0)/len(rt_eeg_channels)\n",
    "\n",
    "rt_filters_eeg = [\n",
    "    ica_rejection,\n",
    "    SpatialFilter(rt_channels_mask),\n",
    "    ButterFilter([1, None], sampling_freq, 1),\n",
    "    CFIRBandEnvelopeDetector([12, 15], sampling_freq, ExponentialSmoother(0.9))\n",
    "]\n",
    "\n",
    "\n",
    "# which channel for the EMG (Muscle)?\n",
    "rt_emg_channels = ['T3', 'T4'] # check if they're not in the bad channels..\n",
    "rt_emg_channels_mask = np.where([ch in rt_eeg_channels for ch in channel_names], 1, 0)/len(rt_eeg_channels)\n",
    "\n",
    "rt_filters_emg = [\n",
    "    SpatialFilter(),\n",
    "    ButterFilter([None, 50], sampling_freq, 1),\n",
    "    CFIRBandEnvelopeDetector([None, 50], sampling_freq, ExponentialSmoother(0.9))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiment\n",
    " - grab the data, apply RT Analysis, send to stimulus computer\n",
    " - press Enter on the Stimulus Computer to get started\n",
    " - subject trans (or should train) ther EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear EEG Data buffer\n",
    "while data_inlet.samples_available(): data_inlet.pull_chunk() \n",
    "\n",
    "# collect some data    \n",
    "np_nf = []\n",
    "w=guis.AcquireData(sampling_freq, channel_names)\n",
    "while w.RUNLOOP:\n",
    "    chunk_data, chunk_times = data_inlet.pull_chunk() # grab from LSL\n",
    "    if chunk_data:  # if there is any data\n",
    "        np_nf.append(chunk_data) # add to our list\n",
    "        w.update(chunk_data) # update the GUI window\n",
    "        \n",
    "        s_eeg = rt_filters_eeg.apply(chunk_data)\n",
    "\n",
    "        tf, audioTF = track_for_eeg_stimuli.check_above_threshold(s_eeg)  # sends markers (should be fast)\n",
    "        s = track_for_eeg_stimuli.send_data_signal(s_eeg) # sends the signal (should also be fast!)\n",
    "\n",
    "        \n",
    "        s_emg = rt_filters_emg.apply(chunk_data)\n",
    "\n",
    "        tfemg, audioTFemg = track_for_emg_stimuli.check_above_threshold(s_emg)  # sends markers (should be fast)\n",
    "        semg = track_for_emg_stimuli.send_data_signal(s_emg) # sends the signal (should also be fast!)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
