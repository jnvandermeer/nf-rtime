{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nftools import guis\n",
    "import pylsl\n",
    "import time\n",
    "import numpy as np\n",
    "import mne, re\n",
    "\n",
    "%matplotlib qt  \n",
    "%gui qt\n",
    "import warnings; warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the EEG Cap\n",
    "\n",
    "- fix the EEG Cap\n",
    "- run the `python raw_eo_data --stream`, followed by `/start`\n",
    "- (re)-start the Cap or USB if it doesn't work, followed by commands above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = openbci_eeg\n",
      "sampling_freq = 125\n",
      "channel_count = 16\n",
      "channel_format = 1\n"
     ]
    }
   ],
   "source": [
    "# make the connection to the EEG Net (EEG Data)\n",
    "data_stream=pylsl.resolve_byprop(\"name\", \"openbci_eeg\", timeout=5.0)\n",
    "if data_stream:\n",
    "    data_inlet=pylsl.stream_inlet(data_stream[0])\n",
    "    stream_info = data_inlet.info()\n",
    "    stream_Fs = stream_info.nominal_srate()\n",
    "    stream_xml = stream_info.desc()\n",
    "    chans_xml = stream_xml.child(\"channels\")\n",
    "    chan_xml_list = []\n",
    "    ch = chans_xml.child(\"channel\")\n",
    "    while ch.name() == \"channel\":\n",
    "        chan_xml_list.append(ch)\n",
    "        ch = ch.next_sibling(\"channel\")\n",
    "    channel_names = [ch_xml.child_value(\"label\") for ch_xml in chan_xml_list]\n",
    "    data_inlet_dt = data_inlet.time_correction(timeout=5.0)\n",
    "    sampling_freq = data_stream[0].nominal_srate()\n",
    "    print('name = %s' % data_stream[0].name())\n",
    "    print('sampling_freq = %d' % sampling_freq)\n",
    "    print('channel_count = %d' % data_stream[0].channel_count())\n",
    "    print('channel_format = %d' % data_stream[0].channel_format())\n",
    "else:\n",
    "    raise Exception('No Data Stream Found - Is your EEG Cap running?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get (~ 2-3 minutes) of Eyes Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=16, n_times=286\n",
      "    Range : 0 ... 285 =      0.000 ...     2.280 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# clear EEG Data buffer\n",
    "while data_inlet.samples_available(): data_inlet.pull_chunk() \n",
    "\n",
    "# collect some data    \n",
    "np_eo = []\n",
    "w=guis.AcquireData(sampling_freq, channel_names)\n",
    "while w.RUNLOOP:\n",
    "    chunk_data, chunk_times = data_inlet.pull_chunk() # grab from LSL\n",
    "    if chunk_data:  # if there is any data\n",
    "        np_eo.append(chunk_data) # add to our list\n",
    "        w.update(chunk_data) # update the GUI window\n",
    "\n",
    "# and we make the MNE data file from it        \n",
    "raw_eo = mne.io.RawArray(np.concatenate(np_eo).T,\n",
    "                        mne.create_info(channel_names, \n",
    "                                    sampling_freq, \n",
    "                                    'eeg', \n",
    "                                    None)\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Bad Channels and Bad Time Intervals\n",
    "- Use the MNE Interface to click channels (those are bad)\n",
    "- Use also the MNE Interface ('a' button) to mark/drag\n",
    "bad segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "raw_eo.plot(scalings='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "channels to remove: []\n",
      "channel mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "number of samples to remove: 0\n",
      "raw original shape: 16, 503\n",
      "np new shape: 503, 16\n",
      "apply filter: 3 to 45\n",
      "Dropped 95 outliers\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=408\n",
      "    Range : 0 ... 407 =      0.000 ...     3.256 secs\n",
      "Ready.\n",
      "Fitting ICA to data using 16 channels (please be patient, this may take a while)\n",
      "Inferring max_pca_components from picks\n",
      "Using all PCA components: 16\n",
      "Computing Extended Infomax ICA\n",
      "Fitting ICA took 0.5s.\n",
      "ICA/CSP time elapsed = 0.5303621292114258s\n",
      "Table drawing time elapsed = 3.503187656402588s\n",
      "Created an ICA Spatial Filter\n",
      "<pynfb.signal_processing.filters.SpatialRejection object at 0x7f1ef0f2fcc0>\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "# extracting the ch names and time information\n",
    "bad_channels = raw_eo.info['bads']\n",
    "bad_segments = [(a['onset'], a['duration']) for a in raw_eo.annotations if re.search('BAD', a['description'])]\n",
    "print(bad_channels)\n",
    "for s in bad_segments: print('%.2g, %.2g' % (s[0], sum(s)))\n",
    "\n",
    "# convert to ch mask; and samples to keep/remove\n",
    "bad_channel_indices = [i for i, ch in enumerate(raw_eo.info['ch_names']) \n",
    "                    if ch in bad_channels]\n",
    "bad_channel_mask = [ch not in bad_channels for ch in channel_names]\n",
    "\n",
    "[range(int(b * sampling_freq), int((b+d) * sampling_freq)) for b, d in bad_segments]\n",
    "\n",
    "if bad_segments:\n",
    "    bad_segment_samples = np.concatenate([range(int(b * sampling_freq), int((b+d) * sampling_freq)) for b, d in bad_segments])\n",
    "else:\n",
    "    bad_segment_samples=[]\n",
    "\n",
    "print('channels to remove: %s' % bad_channel_indices)\n",
    "print('channel mask: ' + repr(bad_channel_mask))\n",
    "print('number of samples to remove: %s' % len(bad_segment_samples))\n",
    "\n",
    "# remove the bad channels and bad samples, make new data matrices:\n",
    "np_eo_forica = raw_eo.copy().get_data().T\n",
    "\n",
    "np_eo_forica = np.delete(np_eo_forica, bad_segment_samples, axis=0)\n",
    "np_eo_forica = np.delete(np_eo_forica, bad_channel_indices, axis=1)\n",
    "\n",
    "print('raw original shape: %d, %d' % raw_eo.get_data().shape)\n",
    "print('np new shape: %d, %d' % np_eo_forica.shape)\n",
    "\n",
    "# # inspect the new data matrix in the viewer\n",
    "# raw_eo_forica = mne.io.RawArray(np_eo_forica.T,\n",
    "#                         mne.create_info([n for n in channel_names if n not in bad_channels], \n",
    "#                                     sampling_freq, \n",
    "#                                     'eeg', \n",
    "#                                     None)\n",
    "#                        )\n",
    "\n",
    "# raw_eo_forica.plot(scalings='auto');\n",
    "\n",
    "from pynfb.protocols.ssd.topomap_selector_ica import ICADialog\n",
    "\n",
    "ica_rejection, _, _, ica_unmixing_matrix, _, _ = ICADialog.get_rejection(\n",
    "    np_eo_forica, \n",
    "    [n for n in channel_names if n not in bad_channels], \n",
    "    sampling_freq,\n",
    "    decomposition=None\n",
    ")\n",
    "\n",
    "ica_rejection = ica_rejection.expand_by_mask(bad_channel_mask)\n",
    "\n",
    "print('Created an ICA Spatial Filter')\n",
    "print(ica_rejection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up the Stimulus on Computer\n",
    "- connect via WiFi\n",
    "    - ip address = 10.42.0.1\n",
    "    - host = stim-pc\n",
    "    - password = PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from callpyff import bcinetwork, bcixml\n",
    "bcinet = bcinetwork.BciNetwork('10.42.0.1', bcinetwork.FC_PORT, bcinetwork.GUI_PORT, 'bcixml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TestD2', 'MovingRhomb', 'EOEC', 'LibetClock', 'BrainWaveTraining_II', 'TobiQLAdapter', 'VisualOddballVE', 'EyetrackerFeedback', 'HexoSpeller', 'P300_Rectangle', 'ERPHex', 'BrainWaveTraining', 'StopVigilanceTask', 'FeedbackCursorArrow', 'TrivialPong', 'CheckerboardVEP', 'HexoSpellerVE', 'BoringClock', 'nback_verbal', 'Lesson01', 'BrainPong', 'CakeSpellerVE', 'MovingRhombGL', 'RestingState', 'NFBasicThermometer', 'RSVPSpeller', 'EEGfMRILocalizer', 'MultiVisualOddball', 'Lesson01b', 'GoalKeeper', 'CenterSpellerVE', 'Oddball', 'EyetrackerRawdata', 'StroopFeedback', 'ERPMatrix', 'Lesson04', 'Lesson05', 'Lesson06', 'VisualOddball', 'Lesson02', 'Lesson03']\n"
     ]
    }
   ],
   "source": [
    "print(bcinet.getAvailableFeedbacks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet.send_init('BrainWaveTraining_II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet.send_signal(bcixml.BciSignal({'EX_TESTNFNOISE': False},None, bcixml.INTERACTION_SIGNAL))\n",
    "bcinet.send_signal(bcixml.BciSignal({'MONITOR_PIXWIDTH': 1366},None, bcixml.INTERACTION_SIGNAL))\n",
    "bcinet.send_signal(bcixml.BciSignal({'MONITOR_PIXHEIGHT': 768},None, bcixml.INTERACTION_SIGNAL))\n",
    "bcinet.send_signal(bcixml.BciSignal({'MONITOR_FULLSCR': True},None, bcixml.INTERACTION_SIGNAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr: 1.00, dur: 0.20\n",
      "bcinet is passed on\n",
      "thr: 10.00, dur: 0.15\n",
      "bcinet is passed on\n"
     ]
    }
   ],
   "source": [
    "# parameters to convert the filtered EEG signal to the stimulus\n",
    "from nftools.nftools import signaltracking\n",
    "track_for_eeg_stimuli = signaltracking.sending_to_nfstim(\n",
    "    thr=1.0, \n",
    "    dur=0.20, \n",
    "    feedback_type='eeg', \n",
    "    max4audio=1.2, \n",
    "    bcinet=bcinet, \n",
    "    st_scaling=10\n",
    ")\n",
    "\n",
    "# parameters to convert the filtered EMG signal to the stimulus\n",
    "track_for_emg_stimuli = signaltracking.sending_to_nfstim(\n",
    "    thr=10, \n",
    "    dur=0.15, \n",
    "    feedback_type='emg', \n",
    "    bcinet=bcinet, \n",
    "    st_scaling=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Real-Time EEG Signal Analysis during NF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynfb.signal_processing.filters import (FilterSequence, \n",
    "                                             CFIRBandEnvelopeDetector, \n",
    "                                             ExponentialSmoother,\n",
    "                                             SpatialFilter,\n",
    "                                             ButterFilter,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Filter Sequence for NF\n",
    "\n",
    "# Which channel do we select for the EEG?\n",
    "rt_eeg_channels = ['C3']\n",
    "rt_eeg_channels_mask = np.where([ch in rt_eeg_channels for ch in channel_names], 1, 0)/len(rt_eeg_channels)\n",
    "\n",
    "preprocess_filters_eeg = FilterSequence([\n",
    "    ica_rejection,\n",
    "    SpatialFilter(rt_eeg_channels_mask),\n",
    "    ButterFilter([1, None], sampling_freq, 1),\n",
    "])\n",
    "envelope_filter_eeg = CFIRBandEnvelopeDetector([12, 15], sampling_freq, ExponentialSmoother(0.9))\n",
    "\n",
    "\n",
    "# which channel for the EMG (Muscle)?\n",
    "rt_emg_channels = ['T3', 'T4'] # check if they're not in the bad channels..\n",
    "rt_emg_channels_mask = np.where([ch in rt_eeg_channels for ch in channel_names], 1, 0)/len(rt_eeg_channels)\n",
    "\n",
    "preprocess_filters_emg = FilterSequence([\n",
    "    SpatialFilter(rt_emg_channels_mask),\n",
    "    ButterFilter([None, 50], sampling_freq, 1),\n",
    "])\n",
    "envelope_filter_emg = CFIRBandEnvelopeDetector([50, 60], sampling_freq, ExponentialSmoother(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-134694.17567956, -134897.54948323, -134839.1716953 ,\n",
       "        -134720.01034385, -134917.65625872, -134760.72948337,\n",
       "        -134803.83833372, -134869.15890461, -134701.97655871,\n",
       "        -134906.08515852]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ButterFilter([1, 60], 128, 1).apply(np.matrix(SpatialFilter(rt_eeg_channels_mask).apply(ica_rejection.apply(chunk_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiment\n",
    " - grab the data, apply RT Analysis, send to stimulus computer\n",
    " - press Enter on the Stimulus Computer to get started\n",
    " - subject trans (or should train) ther EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b095dc4e36e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Apply Filters and draw in our second window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpreprocessed_eeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_filters_eeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0menvelope_eeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvelope_filter_eeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_eeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nf/nfb/pynfb/signal_processing/filters.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilter_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nf/nfb/pynfb/signal_processing/filters.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rt/lib/python3.7/site-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36mlfilter\u001b[0;34m(b, a, x, axis, zi)\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "# clear EEG Data buffer\n",
    "while data_inlet.samples_available(): data_inlet.pull_chunk() \n",
    "\n",
    "# collect some data    \n",
    "np_nf = []\n",
    "w_acquire=guis.AcquireData(sampling_freq, channel_names)\n",
    "# w_analyze=guis.AnalyzeData()\n",
    "\n",
    "while w_acquire.RUNLOOP:\n",
    "    chunk_data, chunk_times = data_inlet.pull_chunk() # grab from LSL\n",
    "    if chunk_data:  # if there is any data\n",
    "        np_nf.append(chunk_data) # add to our list\n",
    "        w.update(chunk_data) # update the GUI window\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Apply Filters and draw in our second window\n",
    "\n",
    "        preprocessed_eeg = preprocess_filters_eeg.apply(chunk_data)\n",
    "        envelope_eeg = envelope_filter_eeg.apply(preprocessed_eeg)\n",
    "\n",
    "        preprocessed_emg = preprocess_filters_emg.apply(chunk_data)\n",
    "        envelope_emg = envelope_filter_eeg.apply(preprocessed_emg)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # interaction with the Stimulus Ciomputer\n",
    "        \n",
    "        visual_markers_eeg, audio_markers_eeg = track_for_eeg_stimuli.check_above_threshold(envelope_eeg)  # sends markers (should be fast)\n",
    "        track_for_eeg_stimuli.send_data_signal(envelope_eeg) # sends the signal (should also be fast!)\n",
    "\n",
    "        \n",
    "        visual_markers_emg, audio_markers_emg = track_for_emg_stimuli.check_above_threshold(envelope_emg)  # sends markers (should be fast)\n",
    "        track_for_emg_stimuli.send_data_signal(s_emg) # sends the signal (should also be fast!)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ab1dbc4593d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocess_filters_eeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/nf/nfb/pynfb/signal_processing/filters.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilter_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nf/nfb/pynfb/signal_processing/filters.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, chunk)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rt/lib/python3.7/site-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36mlfilter\u001b[0;34m(b, a, x, axis, zi)\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "preprocess_filters_eeg.apply(np.array(chunk_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(chunk_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
