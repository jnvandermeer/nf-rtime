{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replaying Old Data\n",
    "\n",
    "- Work under a separate branch with git (i.e. git checkout -b my-new-branch)\n",
    "\n",
    "- Make a new folder in Projects (for your specific purposes)\n",
    "\n",
    "- Copy this ipynb file that folder\n",
    "\n",
    "- The data is stored on L-Drive\n",
    "\n",
    "- the main gist of re-playing existing data is:\n",
    "    - that your first load everything into a big matrix with mne\n",
    "    - then initialize a specific **amp** (i.e., the \"replayamp\")\n",
    "    - then do exactly the same as normal, with a while True loop with calls to amp.get_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the needed stuff:\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import easygui  # popup windows with buttons made easy\n",
    "import mne  # EEGLAB for python\n",
    "from IPython.display import clear_output  # to clear the cell output during while loop\n",
    "import re  # regular expressions\n",
    "import pickle  # to save/load data\n",
    "import dynarray  # a growing numpy array\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "sys.path.append(\"../../mushu\")  # driver for the amps\n",
    "sys.path.append(\"../../mushu/libmushu\")\n",
    "import libmushu\n",
    "\n",
    "sys.path.append(\"../../callpyff\")   # talk to the stimuli\n",
    "from callpyff import bcinetwork, bcixml \n",
    "\n",
    "sys.path.append(\"../../nftools\")  # handy stuff needed for NF\n",
    "from nftools.loopcontrol import LoopState\n",
    "from nftools.analysis import convert_alld_allm_to_mne\n",
    "from nftools.analysis import select_part_from_mne_dataset\n",
    "from nftools.analysis import plot_compare_two_spectra\n",
    "\n",
    "\n",
    "sys.path.append(\"../../wyrm\")  # real-time data analysis\n",
    "from wyrm.types import RingBuffer\n",
    "from wyrm.types import BlockBuffer\n",
    "from wyrm import io\n",
    "from wyrm import processing as proc\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "from collections import deque  # a FILO list useful for plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet = bcinetwork.BciNetwork('localhost', bcinetwork.FC_PORT, bcinetwork.GUI_PORT, 'bcixml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TestD2', 'MovingRhomb', 'LibetClock', 'BrainWaveTraining_II', 'TobiQLAdapter', 'EyetrackerRawdata', 'EyetrackerFeedback', 'HexoSpeller', 'P300_Rectangle', 'ERPHex', 'BrainWaveTraining', 'StopVigilanceTask', 'FeedbackCursorArrow', 'TrivialPong', 'CheckerboardVEP', 'HexoSpellerVE', 'BoringClock', 'nback_verbal', 'VisualOddball', 'BrainPong', 'CakeSpellerVE', 'MovingRhombGL', 'RestingState', 'NFBasicThermometer', 'RSVPSpeller', 'EEGfMRILocalizer', 'Oddball', 'Lesson01b', 'GoalKeeper', 'CenterSpellerVE', 'MultiVisualOddball', 'StroopFeedback', 'ERPMatrix', 'Lesson04', 'Lesson05', 'Lesson06', 'Lesson01', 'Lesson02', 'Lesson03', 'VisualOddballVE']\n"
     ]
    }
   ],
   "source": [
    "feedbacks = bcinet.getAvailableFeedbacks()\n",
    "print(feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet.send_init('BrainWaveTraining_II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MONITOR_NSCREENS': 2,\n",
       " 'MONITOR_HEIGHT': 30.0,\n",
       " 'EX_PATCHCOLOR': 'green',\n",
       " 'MONITOR_WIDTH': 40.0,\n",
       " 'MONITOR_ALLOWGUI': False,\n",
       " 'fontheight': 200,\n",
       " 'EX_EMG_THERMOEDGE': 0.05,\n",
       " 'EX_TESTNFNOISE': True,\n",
       " 'MONITOR_DISTANCE': 70.0,\n",
       " 'LOG_PATHFILE': 'log/bwt.log',\n",
       " 'EX_SQUARESIZE': 0.25,\n",
       " 'EVENT_printToTerminalAllowed': [0, 255],\n",
       " 'EX_TPAUSE': 0.5,\n",
       " 'EX_POINTS_PENALTY': -2,\n",
       " 'EX_TFB': 12.0,\n",
       " 'EX_TXT_COUNTER': [0],\n",
       " 'EVENT_sendLogFile': True,\n",
       " 'EX_NOBSERVE': 10,\n",
       " 'EX_WIN_PARAMS': [0.25],\n",
       " 'EX_SCALING': [0.75, 0.75],\n",
       " 'MONITOR_FLIPVERTICAL': False,\n",
       " 'EX_EV_IGNORE_KEYS': ['5', 't'],\n",
       " 'EX_TJITT': [0.8, 1.3],\n",
       " 'EX_NTRANSFER': 10,\n",
       " 'MONITOR_USEDEGS': False,\n",
       " 'MONITOR_DISPLAYONSCREEN': 1,\n",
       " 'EVENT_sendParallel': True,\n",
       " 'MONITOR_DEGS_HEIGHTBASE': 10,\n",
       " 'EVENT_printToTerminal': True,\n",
       " 'EX_XorV_RESET_POINTS': False,\n",
       " 'EX_BUTTONS': ['lctrl', 'rctrl'],\n",
       " 'EX_SND_LOWESTTONE': 27,\n",
       " 'STARTKEYS': ['return', 't'],\n",
       " 'EX_TESTSIGNALUPDATEINTERVAL': 0.01,\n",
       " 'EVENT_destport': 6050,\n",
       " 'udp_markers_host': '127.0.0.1',\n",
       " 'EX_STAIRCASEMANIPULATION': 'offset',\n",
       " 'EX_TUNING_TYPE': 'thr',\n",
       " 'MONITOR_GAMMA': 1.0,\n",
       " 'EX_NOREGTEXT': 'do not regulate',\n",
       " 'MONITOR_PIXWIDTH': 1280,\n",
       " 'EX_SHOWPOINTS': True,\n",
       " 'EX_EMG_THERMOHEIGHT': 0.2,\n",
       " 'EX_WIN_CONDITION': 'time_above_thr',\n",
       " 'caption': 'EEG - fMRI Localizer',\n",
       " 'EX_TESTSIGNALTYPE': 'sin',\n",
       " 'MONITOR_FLIPHORIZONTAL': False,\n",
       " 'MONITOR_DEGS_WIDTHBASE': 12,\n",
       " 'EVENT_TRIGLOG': 'log/triggerlog.log',\n",
       " 'color': [0, 0, 0],\n",
       " 'udp_markers_port': 12344,\n",
       " 'EX_TUNING_PARAMS': [1.0, 0.0],\n",
       " 'EX_INTERACTIONMODE': 'master',\n",
       " 'EX_NREGULATE': 30,\n",
       " 'EX_COLORGAP': 1,\n",
       " 'EX_STAIRIDENTIFIER': '0001',\n",
       " 'EVENT_sendTcpIp': True,\n",
       " 'EX_THERMOCLIMS': ['c4572e', '4fc42e'],\n",
       " 'EX_NREST': 10,\n",
       " 'EX_TVSP': 0.4,\n",
       " 'EVENT_LPT_TRIGGER_WAIT': 0.005,\n",
       " 'MONITOR_RECORDFRAMEINTERVALS': True,\n",
       " 'CP': {'WIN_CONDITION': 'time_above_thr',\n",
       "  'hitError': [[]],\n",
       "  'hit': [[]],\n",
       "  'emgContainer': [0.1],\n",
       "  'CURRENTTIME': [None],\n",
       "  'instruction': 'arrowup',\n",
       "  'nfsignalContainer': [0],\n",
       "  'TUNING_TYPE': 'thr',\n",
       "  'TJITT': [1],\n",
       "  'EX_TXT_COUNTER': [0],\n",
       "  'corr_incorr': [None],\n",
       "  'emgThrContainer': [0.2],\n",
       "  'TrialType': [None],\n",
       "  'CURRENTPART': [None],\n",
       "  'WIN_PARAMS': [0.25],\n",
       "  'playNFSounds': False,\n",
       "  'TUNING_PARAMS': [1.0, 0.0],\n",
       "  'thrContainer': [0.5]},\n",
       " 'EX_TINSTR': 2.0,\n",
       " 'EX_TESTSIGNALPERIOD': 4,\n",
       " 'EX_EMG_THERMOWIDTH': 0.075,\n",
       " 'EX_NUMBEROFSETS': 6,\n",
       " 'MONITOR_FPS': 60.0,\n",
       " 'EX_SND_HIGHESTTONE': 48,\n",
       " 'EX_GRAPHICSMODE': 'line',\n",
       " 'EX_PR_SLEEPTIME': 0.01,\n",
       " 'LOG_PATHFILE_EVENT': 'log/evsbwt.log',\n",
       " 'SND_LOWESTTONE': 27,\n",
       " 'EX_TMARK': 1.5,\n",
       " 'MONITOR_FULLSCR': False,\n",
       " 'EX_MIXOFSETS': {'transfer': 1, 'train': 3, 'observe': 1, 'rest': 1},\n",
       " 'EX_RUNS': 5,\n",
       " 'EX_THRLINEWIDTH': 2,\n",
       " 'EX_POINTS_REWARD': 10,\n",
       " 'EX_EMG_THERMOCLIMS': ['00ff00', 'ff0000'],\n",
       " 'EX_UPREGTEXT': 'regulate up',\n",
       " 'EVENT_LPTTrigWaitTime': 0.005,\n",
       " 'EVENT_destip': '127.0.0.1',\n",
       " 'EX_SHOWCHECKORCROSSTRANSFER': True,\n",
       " 'MONITOR_PIXHEIGHT': 1024,\n",
       " 'SND_HIGHESTTONE': 48,\n",
       " 'EX_INSTR': 'Upregulate: Focus on moving upwards / more green',\n",
       " 'EVENT_LPTAddress': 888,\n",
       " 'EX_SHOWCHECKORCROSS': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcinet.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet.send_signal(bcixml.BciSignal({'EX_TESTNFNOISE': False},None, bcixml.INTERACTION_SIGNAL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../3_RTMRICWL/trial_data_for_mri_cwl_development_withtrend.set\n",
      "The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n",
      "The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "Events like the following will be dropped entirely: ['Sync On', 'boundary'], 2 in total\n",
      "42/120 event codes could not be mapped to integers. Use the 'event_id' parameter to map such events manually.\n",
      "24 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.\n",
      "Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8eb704f1a035>:10: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-7-8eb704f1a035>:10: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-7-8eb704f1a035>:10: RuntimeWarning: Events like the following will be dropped entirely: ['Sync On', 'boundary'], 2 in total\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-7-8eb704f1a035>:10: RuntimeWarning: 42/120 event codes could not be mapped to integers. Use the 'event_id' parameter to map such events manually.\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-7-8eb704f1a035>:10: RuntimeWarning: 24 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-7-8eb704f1a035>:10: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8eb704f1a035>:12: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n",
      "  raw_fromfile.set_montage(montage)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawEEGLAB  |  None, n_channels x n_times : 39 x 400001 (80.0 sec), ~119.1 MB, data loaded>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the replay notebook - so select a file for playback - this is for brainvision files.\n",
    "\n",
    "# fn=easygui.fileopenbox(default='/media/ldrive/Lab_MichaelB/Johan/nf/rawdata/*.vhdr')\n",
    "fn='../3_RTMRICWL/trial_data_for_mri_cwl_development_withtrend.set'\n",
    "\n",
    "print(fn)\n",
    "\n",
    "\n",
    "\n",
    "raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
    "montage=mne.channels.read_montage('standard_1005', ch_names=raw_fromfile.ch_names)  # always use MNE definitions\n",
    "raw_fromfile.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties of the recording, and what we're doing here:\n",
    "fs = raw_fromfile.info['sfreq']\n",
    "nbchan = raw_fromfile.info['nchan']-1\n",
    "\n",
    "updateTime = 0.1  # run some kind of calculation every X seconds\n",
    "buffSize = 1.0  # run calculation on last X seconds of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5  \n",
    "plt.ion()  # enable widget plots & interactive plots\n",
    "\n",
    "time_in_plot=2.0\n",
    "sy1=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))  # for plotting - the FILO list\n",
    "sy2=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))  # for plotting - the FILO list\n",
    "\n",
    "channel_to_plot=10\n",
    "sx = np.linspace(0, time_in_plot, round(fs * time_in_plot))\n",
    "\n",
    "featuresy1 = deque(np.zeros(round(1/updateTime * time_in_plot)), round(1/updateTime * time_in_plot))\n",
    "featuresx = np.linspace(0, time_in_plot, round(1/updateTime * time_in_plot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time data filtering -- high-pass filter (of 1.0 Hz)\n",
    "\n",
    "f_low = 1.0\n",
    "# f_high = 15.0\n",
    "butter_ord = 3\n",
    "lenchannels = 38\n",
    "\n",
    "#rt_b, rt_a = signal.butter(butter_ord, [f_low / fn, f_high / fn], btype='band')\n",
    "rt_b_hp, rt_a_hp = signal.butter(butter_ord, 2*f_low/fs, btype='high', analog=False)  # a digital high-pass filter\n",
    "rt_zi_hp = proc.lfilter_zi(rt_b_hp, rt_a_hp, lenchannels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time data filtering -- band-pass filter (of 12.0 - 15.0 Hz)\n",
    "\n",
    "f_low = 12.0\n",
    "f_high = 15.0\n",
    "butter_ord = 3\n",
    "lenchannels = 38\n",
    "\n",
    "#rt_b, rt_a = signal.butter(butter_ord, [f_low / fn, f_high / fn], btype='band')\n",
    "rt_b_bp, rt_a_bp = signal.butter(butter_ord, [2*f_low/fs, 2*f_high/fs], btype='band', analog=False)  # a digital high-pass filter\n",
    "rt_zi_bp = proc.lfilter_zi(rt_b_bp, rt_a_bp, lenchannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for replay (warning: need probably a lot of memory)\n",
    "\n",
    "mul_factor = 1.0\n",
    "if 1e-6 in [raw_fromfile.info['chs'][0]['cal'], raw_fromfile.info['chs'][0]['range']]:\n",
    "    mul_factor = 1.0 / 1e-6\n",
    "\n",
    "seed_d=raw_fromfile[:-1,:][0] * mul_factor  # scale the data to seed (so no 1e-6 stuff in the replayed data)\n",
    "seed_d=np.array(seed_d.transpose())\n",
    "seed_ch=raw_fromfile.ch_names[0:-1]\n",
    "seed_fs=raw_fromfile.info['sfreq']\n",
    "\n",
    "# prepare for replay; markers:\n",
    "seed_mdata=np.transpose(raw_fromfile[-1,:][0])\n",
    "seed_m=[[i / raw_fromfile.info['sfreq'] * 1000, int(m[0])] for i, m in enumerate(seed_mdata) if m > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = libmushu.get_amp('replayamp')\n",
    "amp.configure(seed_d, seed_m, seed_ch, seed_fs, realtime=True, blocksize_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alld=dynarray.DynamicArray((None, len(amp.get_channels())))     # data\n",
    "allm=[]     # markers\n",
    "sfreq = amp.get_sampling_frequency()  # sampling frequency\n",
    "ch_names=amp.get_channels()  # channel names\n",
    "\n",
    "markTime=time.time()\n",
    "\n",
    "\n",
    "rb = RingBuffer(buffSize * 1000)  # the buffer containing the last X seconds of data - declared in MILISECONDS\n",
    "totalTime = seed_d.shape[0]/raw_fromfile.info['sfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcinet.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()  # plotting...\n",
    "th=fig.suptitle('')\n",
    "ah1=fig.add_subplot(121)\n",
    "ah2=fig.add_subplot(122)\n",
    "l1, = ah1.plot(sx, sy1)\n",
    "l2, = ah2.plot(sx, sy2)\n",
    "\n",
    "featurefig = plt.figure()\n",
    "featureth=featurefig.suptitle('')\n",
    "featureah=featurefig.add_subplot(111)\n",
    "featurel1, = featureah.plot(featuresx, featuresy1)\n",
    "\n",
    "\n",
    "\n",
    "# l=LoopState(); l.start()\n",
    "markeroffset = 0  # needed to store all data in one big mat/vector\n",
    "t0=time.time()\n",
    "curTime=time.time()\n",
    "st=''\n",
    "while curTime - t0 < totalTime:  # l.get_state() != 'Stop':\n",
    "   \n",
    "    \n",
    "    # keep track of time:\n",
    "    curTime = time.time()\n",
    "    \n",
    "    # this is where you get the data\n",
    "    data, marker = amp.get_data()\n",
    "    \n",
    "    if data.shape[0] > 0:  # this is crucual for remembering filter state.\n",
    "\n",
    "        cnt = io.convert_mushu_data(data, marker, sfreq, ch_names)\n",
    "\n",
    "        f_cnt, rt_zi_bp = proc.lfilter(cnt, rt_b_bp, rt_a_bp, zi=rt_zi_bp)  # real-time data preprocessing...\n",
    "\n",
    "        # plotting...\n",
    "        sy1.extend(cnt.data[:,channel_to_plot])  # to visualize/plot -- s1 and s2 are deque's\n",
    "        sy2.extend(f_cnt.data[:,channel_to_plot])\n",
    "        l1.set_ydata(sy1)\n",
    "        l2.set_ydata(sy2)\n",
    "        msy1=np.mean(sy1)\n",
    "        msy2=np.mean(sy2)\n",
    "        ah1.set_ylim(-100+msy1, 100+msy1)\n",
    "        ah2.set_ylim(-10+msy2, 10+msy2)\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        \n",
    "        # currently has no purpose\n",
    "        newsamples = cnt.data.shape[0]\n",
    "\n",
    "        # append to ringbuffer, so we can calculate features later on on the last N secs/samples of data.\n",
    "        rb.append(f_cnt)\n",
    "\n",
    "        # append it to the big matrix, for saving later on with pickle.\n",
    "        alld.extend(data)\n",
    "        for m in marker:\n",
    "            allm.append([m[0] + markeroffset, m[1]])\n",
    "        markeroffset += newsamples / float(sfreq) * 1000.\n",
    "        \n",
    "\n",
    "\n",
    "        # do the following every 0.1 msec - with with the ringbuffer:\n",
    "        if curTime - markTime > updateTime:\n",
    "            # do Stuff\n",
    "\n",
    "            markTime = curTime\n",
    "            # 1) obtain last 1-second(s)\n",
    "            d = rb.get()\n",
    "\n",
    "            # thomas does stuff here - in this example, we take channel 3 of the data and filter it\n",
    "            feature = np.log10(np.mean(abs(d.data[:,3]))) * 10\n",
    "            featuresy1.append(feature)\n",
    "\n",
    "\n",
    "            # we send the value to BCI/STIM here - but not right now\n",
    "            # bcinet.send_signal(bcixml.BciSignal({'nfsignal': signalToSend},None, bcixml.CONTROL_SIGNAL))\n",
    "            featureMax = 0\n",
    "            featureMin = -6.0\n",
    "            featureScaling = 1/abs(featureMax - featureMin)\n",
    "            featureOffset = (featureMax + featureMin) / 2\n",
    "            signalToSend = featureScaling * (feature - featureOffset)/20\n",
    "\n",
    "            \n",
    "            bcinet.send_signal(bcixml.BciSignal({'nfsignalContainer': signalToSend},None, bcixml.CONTROL_SIGNAL))\n",
    "            \n",
    "            # plot of the feature in a separate figure, to keep track:\n",
    "            featurel1.set_ydata(featuresy1) # plotting the feature stuff\n",
    "            featuremsy1=np.mean(featuresy1)\n",
    "            featureah.set_ylim(-10+featuremsy1, 10+featuremsy1)\n",
    "            featurefig.canvas.draw()\n",
    "            featurefig.canvas.flush_events()\n",
    "            \n",
    "\n",
    "            # clear_output(wait=True)  # write some logging information here\n",
    "            # clear_output clear the output of the cell, but if you do that you also remove the figures, it seems\n",
    "            # so don't do it!\n",
    "            str1 = 'Playing Back - time = %f' % (curTime - t0)\n",
    "            str2 = 'Length Markers: %d' % len(allm)\n",
    "            str3 = '%d, %d' % data.shape\n",
    "            str4 = 'Feature Value: %f' % feature\n",
    "            str5 = 'Scaled Signal for NF: %f' % signalToSend\n",
    "            #print(str1 + '\\n' + str2 + '\\n' + str3 + '\\n' + str4 + '\\n' + str5)\n",
    "            \n",
    "            # print('Length Markers: %d' % len(allm))\n",
    "            # print(data.shape)\n",
    "            th.set_text(str1 + '\\n' + str2 + '\\n' +str3)\n",
    "            featureth.set_text(str4 + '\\n' + str5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SignalToSend' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6f19fc9059d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSignalToSend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SignalToSend' is not defined"
     ]
    }
   ],
   "source": [
    "SignalToSend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17469.169921875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amplifier stopped!\n"
     ]
    }
   ],
   "source": [
    "amp.stop()\n",
    "alld.shrink_to_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to disk, so we can re-load it later:\n",
    "\n",
    "t={'alld':alld, 'allm':allm, 'ch_names':ch_names, 'sfreq':sfreq}\n",
    "with open('c-allm-and-alld.pkl', 'wb') as f:\n",
    "    pickle.dump(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk:\n",
    "\n",
    "with open('c-allm-and-alld.pkl','rb') as f:\n",
    "    t=pickle.load(f)\n",
    "for key in t.keys():\n",
    "    locals()[key] = t[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following EEG sensors did not have a position specified in the selected montage: ['EOG']. Their position has been left untouched.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../nftools/nftools/analysis.py:31: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG']. Their position has been left untouched.\n",
      "  montage=montage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=1287988\n",
      "    Range : 0 ... 1287987 =      0.000 ...   643.994 secs\n",
      "Ready.\n",
      "2000.0\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=1287988\n",
      "    Range : 0 ... 1287987 =      0.000 ...   643.994 secs\n",
      "Ready.\n",
      "2554 events found\n",
      "Event IDs: [  1   2   3   4   5   6   8   9  10  11  12  13  14  15  22  26  31  33\n",
      "  40  41  42  44  45  46  48  51  52  55  56  60  64  81  82  83  84 131\n",
      " 132 133 134 140 201 202 203 204 221 222 223 224 225 226 227 228 229 231\n",
      " 232 233 234 241 242 243 244 245 246 247]\n",
      "2554 events found\n",
      "Event IDs: [  1   2   3   4   5   6   8   9  10  11  12  13  14  15  22  26  31  33\n",
      "  40  41  42  44  45  46  48  51  52  55  56  60  64  81  82  83  84 131\n",
      " 132 133 134 140 201 202 203 204 221 222 223 224 225 226 227 228 229 231\n",
      " 232 233 234 241 242 243 244 245 246 247]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawArray  |  None, n_channels x n_times : 65 x 643994 (644.0 sec), ~319.6 MB, data loaded>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = convert_alld_allm_to_mne(alld, allm, ch_names, sfreq)  # covert to MNE\n",
    "raw.resample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(scalings='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw.set_eeg_reference(ref_channels='average')\n",
    "# better not (yet) - before removing bad channels, since these mess up your data big time: see PREP paper:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter\n",
      "Filter length of 6601 samples (6.601 sec) selected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawArray  |  None, n_channels x n_times : 65 x 643994 (644.0 sec), ~319.6 MB, data loaded>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False,\n",
    "                       stim=False, exclude='bads')\n",
    "\n",
    "raw.notch_filter(np.arange(50, 300, 50), picks=picks, filter_length='auto', phase='zero')\n",
    "# add it (potentialy) some other preprocessing steps here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using markers\n",
      "2554 events found\n",
      "Event IDs: [  1   2   3   4   5   6   8   9  10  11  12  13  14  15  22  26  31  33\n",
      "  40  41  42  44  45  46  48  51  52  55  56  60  64  81  82  83  84 131\n",
      " 132 133 134 140 201 202 203 204 221 222 223 224 225 226 227 228 229 231\n",
      " 232 233 234 241 242 243 244 245 246 247]\n",
      "using boundaries\n",
      "[[-1.01472080e+01 -8.44278033e+00 -1.07179365e+01 ...  1.98669997e+01\n",
      "   2.03968689e+01  1.92453158e+01]\n",
      " [-4.56479432e+00 -3.31983644e+00 -6.15846266e+00 ...  1.25052806e+01\n",
      "   1.42620050e+01  1.40164207e+01]\n",
      " [ 4.45361201e+00  5.80551029e+00  4.33875306e+00 ...  1.81407874e+01\n",
      "   1.93592818e+01  1.62777747e+01]\n",
      " ...\n",
      " [-1.44913762e+01 -1.02954907e+01 -5.91059805e+00 ...  2.84323039e+00\n",
      "   4.15697755e+00  2.47916370e+00]\n",
      " [-3.64098408e+01 -3.26375979e+01 -2.65638678e+01 ... -9.25765146e-01\n",
      "  -2.68660400e+00 -6.18078564e+00]\n",
      " [ 2.00967845e+02 -3.21535690e-02 -3.21516398e-02 ...  1.60703559e-02\n",
      "   1.60722845e-02  1.60742131e-02]]\n",
      "Creating RawArray with float64 data, n_channels=65, n_times=50008\n",
      "    Range : 0 ... 50007 =      0.000 ...    50.007 secs\n",
      "Ready.\n",
      "using markers\n",
      "2554 events found\n",
      "Event IDs: [  1   2   3   4   5   6   8   9  10  11  12  13  14  15  22  26  31  33\n",
      "  40  41  42  44  45  46  48  51  52  55  56  60  64  81  82  83  84 131\n",
      " 132 133 134 140 201 202 203 204 221 222 223 224 225 226 227 228 229 231\n",
      " 232 233 234 241 242 243 244 245 246 247]\n",
      "using boundaries\n",
      "[[ 1.20234668e+01  1.18713090e+01  1.29557119e+01 ...  1.77254027e+01\n",
      "   1.47051177e+01  1.18489462e+01]\n",
      " [-8.77843288e+00 -6.84495890e+00 -8.80226036e+00 ... -4.80254934e-02\n",
      "  -4.13652510e+00 -1.12245718e+00]\n",
      " [ 3.00688923e+00  2.13525440e+00  2.28885893e+00 ... -1.80387309e+01\n",
      "  -1.95353102e+01 -1.94695396e+01]\n",
      " ...\n",
      " [-3.40954116e+01 -2.81009517e+01 -2.89433907e+01 ... -1.17566112e+01\n",
      "  -8.99176260e+00 -9.86825432e+00]\n",
      " [-1.04027306e+01 -5.84374178e+00 -1.42157655e+01 ... -7.22838119e+00\n",
      "  -6.35495546e+00 -7.62007758e+00]\n",
      " [ 2.02967541e+02 -3.24566309e-02 -3.24546845e-02 ...  1.62224779e-02\n",
      "   1.62244238e-02  1.62263697e-02]]\n",
      "Creating RawArray with float64 data, n_channels=65, n_times=50033\n",
      "    Range : 0 ... 50032 =      0.000 ...    50.032 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# split data sets between EO and EC\n",
    "\n",
    "newraw_eo=select_part_from_mne_dataset(raw, markers=[201, 202])\n",
    "newraw_ec=select_part_from_mne_dataset(raw, markers=[203, 204])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.048 (s)\n",
      "Effective window size : 2.048 (s)\n",
      "['Oz', 'O1', 'O2', 'PO8', 'PO7']\n",
      "[29, 30, 60, 61, 62]\n"
     ]
    }
   ],
   "source": [
    "d1=plot_compare_two_spectra(newraw_eo, newraw_ec, freqs=[1, 25], n_fft=2048, n_overlap=512, chs_to_include=['Oz','O1','O2','PO8', 'PO7'], freq_lims_topoplot=[7, 12], pow_lims = [-10, 25]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();plt.plot(newraw_eo[0,0:1000][0].transpose());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "newraw_eo.plot(scalings='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "mne.viz.plot_sensors(newraw_ec.info, show_names=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.048 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims, initial)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/mne/viz/evoked.py:162: RuntimeWarning: invalid value encountered in maximum\n",
      "  rgb /= np.maximum(rgb.max(0), 1e-16)  # avoid div by zero\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/matplotlib/colors.py:251: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any((result < 0) | (result > 1)):\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/matplotlib/colors.py:251: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any((result < 0) | (result > 1)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.048 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims, initial)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/mne/viz/evoked.py:162: RuntimeWarning: invalid value encountered in maximum\n",
      "  rgb /= np.maximum(rgb.max(0), 1e-16)  # avoid div by zero\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/matplotlib/colors.py:251: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any((result < 0) | (result > 1)):\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/matplotlib/colors.py:251: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any((result < 0) | (result > 1)):\n"
     ]
    }
   ],
   "source": [
    "newraw_eo.plot_psd(tmax=np.inf, fmax=250, n_fft=2048);\n",
    "newraw_ec.plot_psd(tmax=np.inf, fmax=250, n_fft=2048);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some attempts at doing ICA\n",
    "#from mne.preprocessing import ICA\n",
    "#method = 'fastica'\n",
    "#n_components = 25\n",
    "#decim = 3\n",
    "#random_state = 23\n",
    "#ica = ICA(n_components=n_components, method=method, random_state=random_state)\n",
    "#print(ica)\n",
    "#\n",
    "#picks_eeg = mne.pick_types(newraw_ec.info, meg=False, eeg=True, eog=False,\n",
    "#                           stim=False, exclude='bads')\n",
    "#reject = dict(eeg=1e-3)\n",
    "#ica.fit(newraw_ec, picks=picks_eeg, decim=decim, reject=reject)\n",
    "#print(ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close all of the figures.\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
