{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replaying Old Data\n",
    "\n",
    "- Work under a separate branch with git (i.e. git checkout -b my-new-branch)\n",
    "\n",
    "- Make a new folder in Projects (for your specific purposes)\n",
    "\n",
    "- Copy this ipynb file that folder\n",
    "\n",
    "- The data is stored on L-Drive\n",
    "\n",
    "- the main gist of re-playing existing data is:\n",
    "    - that your first load everything into a big matrix with mne\n",
    "    - then initialize a specific **amp** (i.e., the \"replayamp\")\n",
    "    - then do exactly the same as normal, with a while True loop with calls to amp.get_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the needed stuff:\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import easygui  # popup windows with buttons made easy\n",
    "import mne  # EEGLAB for python\n",
    "from IPython.display import clear_output  # to clear the cell output during while loop\n",
    "import re  # regular expressions\n",
    "import pickle  # to save/load data\n",
    "import dynarray  # a growing numpy array\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "sys.path.append(\"../../mushu\")  # driver for the amps\n",
    "sys.path.append(\"../../mushu/libmushu\")\n",
    "import libmushu\n",
    "\n",
    "sys.path.append(\"../../nftools\")  # handy stuff needed for NF\n",
    "from nftools.loopcontrol import LoopState\n",
    "from nftools.analysis import convert_alld_allm_to_mne\n",
    "from nftools.analysis import select_part_from_mne_dataset\n",
    "from nftools.analysis import plot_compare_two_spectra\n",
    "\n",
    "\n",
    "sys.path.append(\"../../wyrm\")  # real-time data analysis\n",
    "from wyrm.types import RingBuffer\n",
    "from wyrm.types import BlockBuffer\n",
    "from wyrm import io\n",
    "from wyrm import processing as proc\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "from collections import deque  # a FILO list useful for plotting!\n",
    "\n",
    "### Thomas import ###\n",
    "from numpy.linalg import multi_dot\n",
    "from sklearn.decomposition import FastICA\n",
    "### Thomas import end ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:\\Lab_MichaelB\\Johan\\nf\\rawdata\\CH005\\eeg\\CHall_S05_2018-10-17_15-55-38.vhdr\n",
      "Extracting parameters from L:\\Lab_MichaelB\\Johan\\nf\\rawdata\\CH005\\eeg\\CHall_S05_2018-10-17_15-55-38.vhdr...\n",
      "Setting channel info structure...\n",
      "Currently, 1 trigger(s) will be dropped, such as [Impedance]. Consider using ``event_id`` to parse triggers that do not follow the 'S###' pattern.\n",
      "The following EEG sensors did not have a position specified in the selected montage: ['EOG']. Their position has been left untouched.\n",
      "Reading 0 ... 1169155  =      0.000 ...   584.577 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-dd393dc0a51a>:7: RuntimeWarning: Currently, 1 trigger(s) will be dropped, such as [Impedance]. Consider using ``event_id`` to parse triggers that do not follow the 'S###' pattern.\n",
      "  raw_fromfile = mne.io.read_raw_brainvision(fn)\n",
      "<ipython-input-4-dd393dc0a51a>:9: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG']. Their position has been left untouched.\n",
      "  raw_fromfile.set_montage(montage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n",
      "Setting up band-pass filter from 1 - 35 Hz\n",
      "l_trans_bandwidth chosen to be 1.0 Hz\n",
      "h_trans_bandwidth chosen to be 8.8 Hz\n",
      "Filter length of 6601 samples (3.300 sec) selected\n",
      "Raw_FromFile shape before: (65, 1169156)\n",
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Inferring max_pca_components from picks\n",
      "Using all PCA components: 64\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thomasD\\AppData\\Local\\Continuum\\anaconda3\\envs\\rt\\lib\\site-packages\\mne\\preprocessing\\infomax_.py:192: RuntimeWarning: overflow encountered in exp\n",
      "  y = 1.0 / (1.0 + np.exp(-u))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA took 425.9s.\n",
      "[(64, 64), (64, 64), (64, 64), (1169156, 65)]\n",
      "Raw shape: (65, 1169156)\n",
      "Raw_FromFile shape after: (65, 1169156)\n"
     ]
    }
   ],
   "source": [
    "# this is the replay notebook - so select a file for playback - this is for brainvision files.\n",
    "\n",
    "#fn=easygui.fileopenbox(default='/media/ldrive/Lab_MichaelB/Johan/nf/rawdata/*.vhdr')\n",
    "fn=easygui.fileopenbox(default='/media/ldrive/Lab_MichaelB/Johan/nf/rawdata/*.vhdr')\n",
    "print(fn)\n",
    "\n",
    "raw_fromfile = mne.io.read_raw_brainvision(fn)\n",
    "montage=mne.channels.read_montage('standard_1005', ch_names=raw_fromfile.ch_names)  # always use MNE definitions\n",
    "raw_fromfile.set_montage(montage)\n",
    "\n",
    "\n",
    "### Thomas modified\n",
    "train_length = raw_fromfile.times.shape[0] # length of data to train ICA on for eye blink removal (usually 30)\n",
    "raw_fromfile.load_data()\n",
    "raw_fromfile.set_eeg_reference('average', projection=True)\n",
    "raw_fromfile.apply_proj()\n",
    "raw_fromfile.filter(1., 35., n_jobs=1, fir_design='firwin')\n",
    "\n",
    "raw_blinks = raw_fromfile.copy()\n",
    "raw_blinks.load_data()\n",
    "#raw_blinks.crop(0,train_length)\n",
    "#raw_blinks.filter(1, None)\n",
    "\n",
    "print('Raw_FromFile shape before: {0}'.format(raw_fromfile.get_data().shape))\n",
    "\n",
    "%matplotlib qt5\n",
    "\n",
    "ica = mne.preprocessing.ICA(method=\"infomax\", random_state=1)\n",
    "ica.fit(raw_blinks)\n",
    "ica.plot_sources(inst=raw_blinks)\n",
    "ica.plot_components(inst=raw_blinks)\n",
    "ica_comps = ica.get_sources(inst=raw_blinks).get_data()\n",
    "\n",
    "blks = raw_blinks.get_data().T\n",
    "pca_comps = ica.pca_components_\n",
    "M = ica.mixing_matrix_\n",
    "M_inv = np.linalg.inv(M)\n",
    "S = np.identity(M.shape[0])\n",
    "plt.figure(); plt.plot(blks[:,0]); plt.show()\n",
    "print([M.shape, M_inv.shape, S.shape, blks.shape])\n",
    "print('Raw shape: {0}'.format(raw_blinks.get_data().shape))\n",
    "print('Raw_FromFile shape after: {0}'.format(raw_fromfile.get_data().shape))\n",
    "### Thomas modified end ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "S[[0,1],:] = 0\n",
    "eye_comp = ica_comps[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties of the recording, and what we're doing here:\n",
    "fs = raw_fromfile.info['sfreq']\n",
    "nbchan = raw_fromfile.info['nchan']-1\n",
    "\n",
    "# for updating x-axis\n",
    "data_l = raw_fromfile.get_data().shape[1]\n",
    "data_length = np.linspace(0,data_l,num=data_l)\n",
    "\n",
    "updateTime = 0.1  # run some kind of calculation every X seconds\n",
    "buffSize = 1.0  # run calculation on last X seconds of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5  \n",
    "plt.ion()  # enable widget plots & interactive plots\n",
    "\n",
    "time_in_plot=6\n",
    "sy1=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))  # for plotting - the FILO list\n",
    "sy2=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))  # for plotting - the FILO list\n",
    "sy3=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))\n",
    "\n",
    "channel_to_plot=0\n",
    "sx=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))\n",
    "\n",
    "featuresy1 = deque(np.zeros(round(1/updateTime * time_in_plot)), round(1/updateTime * time_in_plot))\n",
    "featuresx = np.linspace(0, time_in_plot, round(1/updateTime * time_in_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time data filtering -- high-pass filter (of 1.0 Hz)\n",
    "\n",
    "f_low = 1.0\n",
    "# f_high = 15.0\n",
    "butter_ord = 3\n",
    "lenchannels = 64\n",
    "\n",
    "#rt_b, rt_a = signal.butter(butter_ord, [f_low / fn, f_high / fn], btype='band')\n",
    "rt_b_hp, rt_a_hp = signal.butter(butter_ord, 2*f_low/fs, btype='high', analog=False)  # a digital high-pass filter\n",
    "rt_zi_hp = proc.lfilter_zi(rt_b_hp, rt_a_hp, lenchannels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time data filtering -- band-pass filter (of 12.0 - 15.0 Hz)\n",
    "\n",
    "f_low = 12.0\n",
    "f_high = 15.0\n",
    "butter_ord = 3\n",
    "lenchannels = 64\n",
    "\n",
    "#rt_b, rt_a = signal.butter(butter_ord, [f_low / fn, f_high / fn], btype='band')\n",
    "rt_b_bp, rt_a_bp = signal.butter(butter_ord, [2*f_low/fs, 2*f_high/fs], btype='band', analog=False)  # a digital high-pass filter\n",
    "rt_zi_bp = proc.lfilter_zi(rt_b_bp, rt_a_bp, lenchannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for replay (warning: need probably a lot of memory)\n",
    "\n",
    "mul_factor = 1.0\n",
    "if 1e-6 in [raw_fromfile.info['chs'][0]['cal'], raw_fromfile.info['chs'][0]['range']]:\n",
    "    mul_factor = 1.0 / 1e-6\n",
    "\n",
    "seed_d=raw_fromfile[:-1,:][0] * mul_factor  # scale the data to seed (so no 1e-6 stuff in the replayed data)\n",
    "seed_d=np.array(seed_d.transpose())\n",
    "seed_ch=raw_fromfile.ch_names[0:-1]\n",
    "seed_fs=raw_fromfile.info['sfreq']\n",
    "\n",
    "# prepare for replay; markers:\n",
    "seed_mdata=np.transpose(raw_fromfile[-1,:][0])\n",
    "seed_m=[[i / raw_fromfile.info['sfreq'] * 1000, int(m[0])] for i, m in enumerate(seed_mdata) if m > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = libmushu.get_amp('replayamp')\n",
    "amp.configure(seed_d, seed_m, seed_ch, seed_fs, realtime=True, blocksize_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alld=dynarray.DynamicArray((None, len(amp.get_channels())))     # data\n",
    "allm=[]     # markers\n",
    "sfreq = amp.get_sampling_frequency()  # sampling frequency\n",
    "ch_names=amp.get_channels()  # channel names\n",
    "\n",
    "markTime=time.time()\n",
    "\n",
    "rb = RingBuffer(buffSize * 1000)  # the buffer containing the last X seconds of data - declared in MILISECONDS\n",
    "totalTime = seed_d.shape[0]/raw_fromfile.info['sfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,12))  # plotting...\n",
    "th=fig.suptitle('', fontsize=16)\n",
    "ah1=fig.add_subplot(211)\n",
    "ah2=fig.add_subplot(212)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "ah1.set_title(\"Fp1\", fontsize=16, weight='bold')\n",
    "ah2.set_title(\"ICA component (eye blink)\", fontsize=16, weight='bold')\n",
    "ah1.set_xlabel(\"Time [s]\", fontsize=15)\n",
    "ah1.set_ylabel(\"Voltage [\\u03BCV]\", fontsize=15)\n",
    "ah2.set_xlabel(\"Time [s]\", fontsize=15)\n",
    "ah2.set_ylabel(\"Voltage [\\u03BCV]\", fontsize=15)\n",
    "ah1.tick_params(axis='both', labelsize=13)\n",
    "ah2.tick_params(axis='both', labelsize=13)\n",
    "ah1.xaxis.labelpad = 10\n",
    "ah2.xaxis.labelpad = 10\n",
    "\n",
    "l1, = ah1.plot(sx, sy1, color='b', label='Raw')\n",
    "l2, = ah1.plot(sx, sy2, color='r', label='Corrected')\n",
    "l3, = ah2.plot(sx, sy3)\n",
    "\n",
    "ah1.legend(fontsize=14)\n",
    "\n",
    "featurefig = plt.figure()\n",
    "featureth=featurefig.suptitle('')\n",
    "featureah=featurefig.add_subplot(111)\n",
    "featurel1, = featureah.plot(featuresx, featuresy1)\n",
    "\n",
    "# l=LoopState(); l.start()\n",
    "markeroffset = 0  # needed to store all data in one big mat/vector\n",
    "t0=time.time()\n",
    "curTime=time.time()\n",
    "st=''\n",
    "\n",
    "x_data=0\n",
    "while curTime - t0 < totalTime:  # l.get_state() != 'Stop':\n",
    "   \n",
    "    # keep track of time:\n",
    "    curTime = time.time()\n",
    "    \n",
    "    # this is where you get the data\n",
    "    data, marker = amp.get_data()\n",
    "    \n",
    "    if data.shape[0] > 0:  # this is crucial for remembering filter state.\n",
    "        \n",
    "        cnt = io.convert_mushu_data(data, marker, sfreq, ch_names)\n",
    "\n",
    "        f_cnt, rt_zi_bp = proc.lfilter(cnt, rt_b_bp, rt_a_bp, zi=rt_zi_bp)  # real-time data preprocessing...        \n",
    "        \n",
    "        \n",
    "        # plotting...\n",
    "        \n",
    "        eb_data = cnt.data[:,channel_to_plot]\n",
    "        \n",
    "        data_corrected = multi_dot([pca_comps.T, M, S, M_inv, pca_comps, cnt.data.T])\n",
    "        \n",
    "        sy1.extend(eb_data)  # to visualize/plot -- sy1 and sy2 are deque's\n",
    "        sy2.extend(data_corrected[channel_to_plot,:])\n",
    "        sy3.extend(eye_comp[x_data:x_data+len(eb_data)])\n",
    "        sx.extend(data_length[x_data:x_data+len(eb_data)]/fs)\n",
    "        \n",
    "        l1.set_ydata(sy1)  \n",
    "        l2.set_ydata(sy2)\n",
    "        l3.set_ydata(sy3)\n",
    "        l1.set_xdata(sx)\n",
    "        l2.set_xdata(sx)\n",
    "        l3.set_xdata(sx)\n",
    "        \n",
    "        msy1=np.mean(sy1)\n",
    "        msy2=np.mean(sy2)\n",
    "        msy3=np.mean(sy3)\n",
    "         \n",
    "        ah1.set_ylim(-150+msy1, 200+msy1)\n",
    "        ah2.set_ylim(-50+msy3, 50+msy3)\n",
    "\n",
    "        ah1.set_xlim(min(sx), max(sx))\n",
    "        ah2.set_xlim(min(sx), max(sx))\n",
    "        \n",
    "        x_data += len(eb_data)\n",
    "        \n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        \n",
    "        # currently has no purpose\n",
    "        newsamples = cnt.data.shape[0]\n",
    "\n",
    "        # append to ringbuffer, so we can calculate features later on on the last N secs/samples of data.\n",
    "        rb.append(f_cnt)\n",
    "\n",
    "        # append it to the big matrix, for saving later on with pickle.\n",
    "        alld.extend(data)\n",
    "        for m in marker:\n",
    "            allm.append([m[0] + markeroffset, m[1]])\n",
    "        markeroffset += newsamples / float(sfreq) * 1000.\n",
    "        \n",
    "\n",
    "\n",
    "        # do the following every 0.1 msec - with with the ringbuffer:\n",
    "        if curTime - markTime > updateTime:\n",
    "            # do Stuff\n",
    "\n",
    "            markTime = curTime\n",
    "            # 1) obtain last 1-second(s)\n",
    "            d = rb.get()\n",
    "\n",
    "            # thomas does stuff here - in this example, we take channel 1 of the data and filter it\n",
    "            feature = np.log10(np.mean(abs(d.data[:,0]))) * 10\n",
    "            featuresy1.append(feature)\n",
    "            \n",
    "            # we send the value to BCI/STIM here - but not right now\n",
    "            # bcinet.send_signal(bcixml.BciSignal({'nfsignal': signalToSend},None, bcixml.CONTROL_SIGNAL))\n",
    "            featureMax = 0\n",
    "            featureMin = -6.0\n",
    "            featureScaling = 1/abs(featureMax - featureMin)\n",
    "            featureOffset = (featureMax + featureMin) / 2\n",
    "            signalToSend = featureScaling * (feature - featureOffset)\n",
    "\n",
    "            # plot of the feature in a separate figure, to keep track:\n",
    "            featurel1.set_ydata(featuresy1) # plotting the feature stuff\n",
    "            featuremsy1=np.mean(featuresy1)\n",
    "            featureah.set_ylim(-10+featuremsy1, 10+featuremsy1)\n",
    "            \n",
    "            featurefig.canvas.draw()\n",
    "            featurefig.canvas.flush_events()\n",
    "\n",
    "            # clear_output(wait=True)  # write some logging information here\n",
    "            # clear_output clear the output of the cell, but if you do that you also remove the figures, it seems\n",
    "            # so don't do it!\n",
    "            str1 = '\\nt = %f' % (curTime - t0)\n",
    "            #str2 = 'Length Markers: %d' % len(allm)\n",
    "            #str3 = '%d, %d' % data.shape\n",
    "            str4 = 'Feature Value: %f' % feature\n",
    "            str5 = 'Scaled Signal for NF: %f' % signalToSend\n",
    "            #str6 = 'Eyeblinks: %d' % eyeblinks\n",
    "            #print(str1 + '\\n' + str2 + '\\n' + str3 + '\\n' + str4 + '\\n' + str5)\n",
    "            \n",
    "            # print('Length Markers: %d' % len(allm))\n",
    "            # print(data.shape)\n",
    "            #th.set_text(str1 + '\\n' + str2 + '\\n' +str3 + '\\n' + str6 + '\\n')\n",
    "            th.set_text(str1 + 's\\n')\n",
    "            featureth.set_text(str4 + '\\n' + str5)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 623\n"
     ]
    }
   ],
   "source": [
    "len(featuresy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amplifier stopped!\n"
     ]
    }
   ],
   "source": [
    "amp.stop()\n",
    "alld.shrink_to_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to disk, so we can re-load it later:\n",
    "\n",
    "t={'alld':alld, 'allm':allm, 'ch_names':ch_names, 'sfreq':sfreq}\n",
    "with open('c-allm-and-alld.pkl', 'wb') as f:\n",
    "    pickle.dump(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk:\n",
    "\n",
    "with open('c-allm-and-alld.pkl','rb') as f:\n",
    "    t=pickle.load(f)\n",
    "for key in t.keys():\n",
    "    locals()[key] = t[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following EEG sensors did not have a position specified in the selected montage: ['EOG']. Their position has been left untouched.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../nftools\\nftools\\analysis.py:31: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG']. Their position has been left untouched.\n",
      "  montage=montage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=1169156\n",
      "    Range : 0 ... 1169155 =      0.000 ...   584.577 secs\n",
      "Ready.\n",
      "2000.0\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=1169156\n",
      "    Range : 0 ... 1169155 =      0.000 ...   584.577 secs\n",
      "Ready.\n",
      "1 events found\n",
      "Event IDs: [1001]\n",
      "1 events found\n",
      "Event IDs: [1001]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawArray  |  None, n_channels x n_times : 65 x 584578 (584.6 sec), ~290.1 MB, data loaded>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = convert_alld_allm_to_mne(alld, allm, ch_names, sfreq)  # covert to MNE\n",
    "raw.resample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(scalings='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw.set_eeg_reference(ref_channels='average')\n",
    "# better not (yet) - before removing bad channels, since these mess up your data big time: see PREP paper:\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter\n",
      "Filter length of 6601 samples (6.601 sec) selected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawArray  |  None, n_channels x n_times : 65 x 584578 (584.6 sec), ~290.1 MB, data loaded>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False,\n",
    "                       stim=False, exclude='bads')\n",
    "\n",
    "raw.notch_filter(np.arange(50, 300, 50), picks=picks, filter_length='auto', phase='zero')\n",
    "# add it (potentialy) some other preprocessing steps here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using markers\n",
      "1 events found\n",
      "Event IDs: [1001]\n",
      "using boundaries\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-a83fb0fd22d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# split data sets between EO and EC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnewraw_eo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselect_part_from_mne_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m201\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m202\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnewraw_ec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselect_part_from_mne_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m203\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m204\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\nf\\nf-rtime\\nftools\\nftools\\analysis.py\u001b[0m in \u001b[0;36mselect_part_from_mne_dataset\u001b[1;34m(rawin, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cannot find nice segments'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mnewraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_part_from_mne_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\nf\\nf-rtime\\nftools\\nftools\\analysis.py\u001b[0m in \u001b[0;36mselect_part_from_mne_dataset\u001b[1;34m(rawin, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mnewdat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboundaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboundaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# split data sets between EO and EC\n",
    "\n",
    "newraw_eo=select_part_from_mne_dataset(raw, markers=[201, 202])\n",
    "newraw_ec=select_part_from_mne_dataset(raw, markers=[203, 204])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newraw_eo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9075291662c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot_compare_two_spectra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewraw_eo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewraw_ec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_overlap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchs_to_include\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Oz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'O1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_lims_topoplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpow_lims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'newraw_eo' is not defined"
     ]
    }
   ],
   "source": [
    "d1=plot_compare_two_spectra(newraw_eo, newraw_ec, freqs=[1, 25], n_fft=2048, n_overlap=512, chs_to_include=['Oz','O1'], freq_lims_topoplot=[7, 12], pow_lims = [-10, 25]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newraw_eo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e1e7dea48da8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewraw_eo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'newraw_eo' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure();plt.plot(newraw_eo[0,0:1000][0].transpose());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newraw_eo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1083063e3741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewraw_eo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'newraw_eo' is not defined"
     ]
    }
   ],
   "source": [
    "newraw_eo.plot(scalings='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newraw_ec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a1a7599f207c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_sensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewraw_ec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'newraw_ec' is not defined"
     ]
    }
   ],
   "source": [
    "mne.viz.plot_sensors(newraw_ec.info, show_names=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.048 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thomasD\\AppData\\Local\\Continuum\\anaconda3\\envs\\rt\\lib\\site-packages\\mne\\viz\\evoked.py:162: RuntimeWarning: invalid value encountered in maximum\n",
      "  rgb /= np.maximum(rgb.max(0), 1e-16)  # avoid div by zero\n",
      "C:\\Users\\thomasD\\AppData\\Local\\Continuum\\anaconda3\\envs\\rt\\lib\\site-packages\\matplotlib\\colors.py:233: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any((result < 0) | (result > 1)):\n",
      "C:\\Users\\thomasD\\AppData\\Local\\Continuum\\anaconda3\\envs\\rt\\lib\\site-packages\\matplotlib\\colors.py:233: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any((result < 0) | (result > 1)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.048 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thomasD\\AppData\\Local\\Continuum\\anaconda3\\envs\\rt\\lib\\site-packages\\mne\\viz\\evoked.py:162: RuntimeWarning: invalid value encountered in maximum\n",
      "  rgb /= np.maximum(rgb.max(0), 1e-16)  # avoid div by zero\n",
      "C:\\Users\\thomasD\\AppData\\Local\\Continuum\\anaconda3\\envs\\rt\\lib\\site-packages\\matplotlib\\colors.py:233: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any((result < 0) | (result > 1)):\n",
      "C:\\Users\\thomasD\\AppData\\Local\\Continuum\\anaconda3\\envs\\rt\\lib\\site-packages\\matplotlib\\colors.py:233: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any((result < 0) | (result > 1)):\n"
     ]
    }
   ],
   "source": [
    "newraw_eo.plot_psd(tmax=np.inf, fmax=250, n_fft=2048);\n",
    "newraw_ec.plot_psd(tmax=np.inf, fmax=250, n_fft=2048);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some attempts at doing ICA\n",
    "#from mne.preprocessing import ICA\n",
    "#method = 'fastica'\n",
    "#n_components = 25\n",
    "#decim = 3\n",
    "#random_state = 23\n",
    "#ica = ICA(n_components=n_components, method=method, random_state=random_state)\n",
    "#print(ica)\n",
    "#\n",
    "#picks_eeg = mne.pick_types(newraw_ec.info, meg=False, eeg=True, eog=False,\n",
    "#                           stim=False, exclude='bads')\n",
    "#reject = dict(eeg=1e-3)\n",
    "#ica.fit(newraw_ec, picks=picks_eeg, decim=decim, reject=reject)\n",
    "#print(ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close all of the figures.\n",
    "%matplotlib qt5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
