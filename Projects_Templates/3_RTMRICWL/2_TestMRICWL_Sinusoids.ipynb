{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replaying Old Data\n",
    "\n",
    "- Work under a separate branch with git (i.e. git checkout -b my-new-branch)\n",
    "\n",
    "- Make a new folder in Projects (for your specific purposes)\n",
    "\n",
    "- Copy this ipynb file that folder\n",
    "\n",
    "- The data is stored on L-Drive\n",
    "\n",
    "- the main gist of re-playing existing data is:\n",
    "    - that your first load everything into a big matrix with mne\n",
    "    - then initialize a specific **amp** (i.e., the \"replayamp\")\n",
    "    - then do exactly the same as normal, with a while True loop with calls to amp.get_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the needed stuff:\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import easygui  # popup windows with buttons made easy\n",
    "import mne  # EEGLAB for python\n",
    "from IPython.display import clear_output  # to clear the cell output during while loop\n",
    "import re  # regular expressions\n",
    "import pickle  # to save/load data\n",
    "import dynarray  # a growing numpy array\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "sys.path.append(\"../../mushu\")  # driver for the amps\n",
    "sys.path.append(\"../../mushu/libmushu\")\n",
    "import libmushu\n",
    "\n",
    "sys.path.append(\"../../nftools\")  # handy stuff needed for NF\n",
    "from nftools.loopcontrol import LoopState\n",
    "from nftools.analysis import convert_alld_allm_to_mne\n",
    "from nftools.analysis import select_part_from_mne_dataset\n",
    "from nftools.analysis import plot_compare_two_spectra\n",
    "\n",
    "\n",
    "sys.path.append(\"../../wyrm\")  # real-time data analysis\n",
    "from wyrm.types import RingBuffer\n",
    "from wyrm.types import BlockBuffer\n",
    "from wyrm import io\n",
    "from wyrm import processing as proc\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "from collections import deque  # a FILO list useful for plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_data_for_mri_cwl_development_withtrend.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-0131e4cfeebe>:9: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-2-0131e4cfeebe>:9: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "/home/johan/.conda/envs/rt/lib/python3.7/site-packages/mne/utils/docs.py:824: DeprecationWarning: Function read_montage is deprecated; ``read_montage`` is deprecated and will be removed in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_custom_montage``, or ``read_dig_captrack`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/johan/.conda/envs/rt/lib/python3.7/site-packages/mne/utils/docs.py:807: DeprecationWarning: Class Montage is deprecated; Montage class is deprecated and will be removed in v0.20. Please use DigMontage instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "<ipython-input-2-0131e4cfeebe>:11: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  raw_fromfile.set_montage(montage)\n",
      "<ipython-input-2-0131e4cfeebe>:11: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n",
      "  raw_fromfile.set_montage(montage)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawEEGLAB  |  trial_data_for_mri_cwl_development_withtrend.set, n_channels x n_times : 38 x 400001 (80.0 sec), ~116.1 MB, data loaded>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the replay notebook - so select a file for playback - this is for eeglab files.\n",
    "\n",
    "#fn=easygui.fileopenbox(default='*.set')\n",
    "fn='trial_data_for_mri_cwl_development_withtrend.set'\n",
    "# fn='eoec_withsins_30hT.set'\n",
    "#fn='trio2_eoec_outside_before.set'\n",
    "print(fn)\n",
    "\n",
    "raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
    "montage=mne.channels.read_montage('standard_1005', ch_names=raw_fromfile.ch_names)  # always use MNE definitions\n",
    "raw_fromfile.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RawEEGLAB  |  trial_data_for_mri_cwl_development_withtrend.set, n_channels x n_times : 38 x 400001 (80.0 sec), ~116.1 MB, data loaded>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_fromfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties of the recording, and some properties of the While Loop:\n",
    "fs = raw_fromfile.info['sfreq']\n",
    "nbchan = raw_fromfile.info['nchan']-1\n",
    "updateTime = 0.1  # run some kind of calculation every X seconds\n",
    "buffSize = 1.0  # run calculation on last X seconds of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: qt5. Using qt instead.\n"
     ]
    }
   ],
   "source": [
    "# preparation to plot stuff in real time:\n",
    "%matplotlib qt5 \n",
    "plt.ion()  # enable widget plots & interactive plots\n",
    "\n",
    "time_in_plot=2.0  # how much time in x-axis\n",
    "sy1=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))  # for plotting - the FILO list\n",
    "sy2=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))  # for plotting - the FILO list\n",
    "sy3=deque(np.zeros(round(fs/10 * time_in_plot)), round(fs/10 * time_in_plot))  # for plotting - the FILO list\n",
    "\n",
    "channel_to_plot=1\n",
    "sx = np.linspace(0, time_in_plot, round(fs * time_in_plot))\n",
    "sx2 = np.linspace(0, time_in_plot, round(fs/10* time_in_plot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time data filtering -- high-pass filter (of 1.0 Hz)\n",
    "\n",
    "f_low = 1.0\n",
    "# f_high = 15.0\n",
    "butter_ord = 3\n",
    "lenchannels = nbchan\n",
    "\n",
    "#rt_b, rt_a = signal.butter(butter_ord, [f_low / fn, f_high / fn], btype='band')\n",
    "rt_b_hp, rt_a_hp = signal.butter(butter_ord, 2*f_low/fs, btype='high', analog=False)  # a digital high-pass filter\n",
    "rt_zi_hp = proc.lfilter_zi(rt_b_hp, rt_a_hp, lenchannels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time data filtering -- band-pass filter (of 12.0 - 15.0 Hz)\n",
    "\n",
    "f_low = 12.0\n",
    "f_high = 15.0\n",
    "butter_ord = 3\n",
    "lenchannels = nbchan\n",
    "\n",
    "#rt_b, rt_a = signal.butter(butter_ord, [f_low / fn, f_high / fn], btype='band')\n",
    "rt_b_bp, rt_a_bp = signal.butter(butter_ord, [2*f_low/fs, 2*f_high/fs], btype='band', analog=False)  # a digital high-pass filter\n",
    "rt_zi_bp = proc.lfilter_zi(rt_b_bp, rt_a_bp, lenchannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for replay (warning: need probably a lot of memory)\n",
    "\n",
    "mul_factor = 1.0\n",
    "if 1e-6 in [raw_fromfile.info['chs'][0]['cal'], raw_fromfile.info['chs'][0]['range']]:\n",
    "    mul_factor = 1.0 / 1e-6\n",
    "\n",
    "seed_d=raw_fromfile[:-1,:][0] * mul_factor  # scale the data to seed (so no 1e-6 stuff in the replayed data)\n",
    "seed_d=np.array(seed_d.transpose())\n",
    "seed_ch=raw_fromfile.ch_names[0:-1]\n",
    "seed_fs=raw_fromfile.info['sfreq']\n",
    "\n",
    "# prepare for replay; markers:\n",
    "seed_mdata=np.transpose(raw_fromfile[-1,:][0])\n",
    "seed_m=[[i / raw_fromfile.info['sfreq'] * 1000, int(m[0])] for i, m in enumerate(seed_mdata) if m > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = libmushu.get_amp('replayamp')\n",
    "amp.configure(seed_d, seed_m, seed_ch, seed_fs, realtime=True, blocksize_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rtfilters import HPF, LPF, BPF, MR, CWL, RESAMPLESAFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f': 1.0, 'fs': 5000, 'order': 3, 'nbchan': 37}\n",
      "{'trsamples': 9750, 'N_thr': 5, 'corr_thr': 0.995, 'forget': 5, 'highpass': [], 'ncorrvalues': 1000}\n",
      "{'f': 125, 'fs': 5000, 'order': 3, 'nbchan': 37}\n",
      "{'fs_source': 5000, 'fs_target': 500}\n",
      "{'seconds_in_window': 6.0, 'tdelay': 0.05, 'icws': [32, 33, 34], 'ichs': [1, 2, 3, 4], 'fs': 500, 'highpass': [], 'saveglms': True}\n"
     ]
    }
   ],
   "source": [
    "hpf=HPF(f=1.0, fs=5000, order=3, nbchan=37)\n",
    "mr=MR(trsamples=9750, N_thr=5, corr_thr = 0.995, forget=5, highpass=[], ncorrvalues=1000)\n",
    "lpf=LPF(f=125, fs=5000, order=3, nbchan=37)\n",
    "resample=RESAMPLESAFE(fs_source=5000, fs_target=500)\n",
    "#cwl=CWL(seconds_in_window=6.0, tdelay=0.050, ichs=list(range(30)), icws=list(range(32,38)), fs=500, highpass=[3, 1.0, 500], saveglms=False)\n",
    "cwl=CWL(seconds_in_window=6.0, tdelay=0.050, ichs=[1,2,3,4], icws=[32,33,34], fs=500, highpass=[], saveglms=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f': 1.0, 'fs': 5000, 'order': 3, 'nbchan': 37}\n",
      "{'trsamples': 9750, 'N_thr': 5, 'corr_thr': 0.995, 'forget': 5, 'highpass': [], 'ncorrvalues': 1000}\n",
      "{'f': 125, 'fs': 5000, 'order': 3, 'nbchan': 37}\n",
      "{'fs_source': 5000, 'fs_target': 500}\n",
      "{'seconds_in_window': 6.0, 'tdelay': 0.05, 'icws': range(32, 27), 'ichs': range(0, 30), 'fs': 500, 'highpass': [], 'saveglms': True}\n",
      "saving GLM: glm1573081639\n",
      "saving GLM: glm1573081642\n",
      "saving GLM: glm1573081645\n",
      "saving GLM: glm1573081648\n",
      "saving GLM: glm1573081651\n",
      "saving GLM: glm1573081654\n",
      "saving GLM: glm1573081657\n",
      "saving GLM: glm1573081660\n",
      "saving GLM: glm1573081663\n",
      "saving GLM: glm1573081666\n",
      "saving GLM: glm1573081669\n",
      "saving GLM: glm1573081672\n",
      "saving GLM: glm1573081675\n"
     ]
    }
   ],
   "source": [
    "hpf=HPF(f=1.0, fs=5000, order=3, nbchan=37)\n",
    "#bpf=BPF(f=[12.0, 15.0], fs=5000, order=3, nbchan=38)\n",
    "#mr=MR(trsamples=10000, N_thr=5, corr_thr = 0.995, forget=6)\n",
    "mr=MR(trsamples=9750, N_thr=5, corr_thr = 0.995, forget=5, highpass=[], ncorrvalues= 1000)\n",
    "lpf=LPF(f=125, fs=5000, order=3, nbchan=37)\n",
    "resample=RESAMPLESAFE(fs_source=5000, fs_target=500)\n",
    "#cwl=CWL(seconds_in_window=6.0, tdelay=0.050, ichs=list(range(30)), icws=list(range(32,38)), fs=500, highpass=[3, 1.0, 500], saveglms=False)\n",
    "cwl=CWL(seconds_in_window=6.0, tdelay=0.050, ichs=range(30), icws=range(32,27), fs=500, highpass=[], saveglms=True)\n",
    "\n",
    "# there are several recommendations to follow when building your MRI artifact removal.\n",
    "# it IS possible to do DC measurements in the MRI, but signal quality of MRI correction will suffer (only a little bit!) due to necessity of\n",
    "# applying HPF on data for MRI artifact considerations, and absence of any filter on the data that is corrected.\n",
    "# better to use hpf separately on data --> THEN MRI correction without any filters, than NO hpf and using hpf within the mr correction\n",
    "# however, the latter I still implement in case of SCP NF - when you have to use the second option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='blabla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saving: blabla'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'saving: %s' % fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp.get_sampling_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLoop():\n",
    "    alld=dynarray.DynamicArray((None, len(amp.get_channels())))     # the growing numpy data matrix\n",
    "    allm=[]     # markers\n",
    "    sfreq = amp.get_sampling_frequency()  # sampling frequency\n",
    "    ch_names=amp.get_channels()  # channel names\n",
    "\n",
    "    rb = RingBuffer(buffSize * 1000)  # the buffer containing the last X seconds of data - declared in MILISECONDS\n",
    "    totalTime = seed_d.shape[0]/raw_fromfile.info['sfreq']\n",
    "\n",
    "    fig=plt.figure()  # plotting...\n",
    "    th=fig.suptitle('')\n",
    "    ah1=fig.add_subplot(131)\n",
    "    ah2=fig.add_subplot(132)\n",
    "    ah3=fig.add_subplot(133)\n",
    "    l1, = ah1.plot(sx, sy1)\n",
    "    l2, = ah2.plot(sx, sy2)\n",
    "    l3, = ah3.plot(sx2, sy3)\n",
    "\n",
    "\n",
    "    # l=LoopState(); l.start()\n",
    "    markeroffset = 0  # needed to store all data in one big mat/vector\n",
    "    t0=time.time()\n",
    "    curTime=time.time()\n",
    "    markTime=time.time()\n",
    "    st=''\n",
    "    i=0; fnames=[] # for making a movie...\n",
    "    while curTime - t0 < totalTime:  # l.get_state() != 'Stop':\n",
    "\n",
    "\n",
    "        # keep track of time:\n",
    "        curTime = time.time()\n",
    "\n",
    "        # this is where you get the data\n",
    "        data, marker = amp.get_data()\n",
    "\n",
    "\n",
    "        if data.shape[0] > 0:  # this is crucial for remembering filter state.\n",
    "\n",
    "\n",
    "            data2=hpf.handle(data)\n",
    "            data3=mr.handle(data2)\n",
    "            data4=lpf.handle(data3)\n",
    "            data5=resample.handle(data4)\n",
    "            data6=cwl.handle(data5)\n",
    "\n",
    "            # something like this:\n",
    "            #filterchain = [HPFilter, MRFilter, LPFilter, ResampleFilter, HPFilter, CWLFilter]\n",
    "\n",
    "            #corr_data = ProcessFilters(chain, (data, marker))\n",
    "\n",
    "\n",
    "            # use case -- first using the MR Corrector\n",
    "            #mr_data = MRFilter.filter(data)\n",
    "\n",
    "            # then -- using the CWL corrector\n",
    "            #cwl_mr_data = CWLFilter.filter(data)\n",
    "\n",
    "\n",
    "            #dataf, rt_zi_bp = signal.lfilter(rt_b_bp, rt_a_bp, data, axis=0, zi=rt_zi_bp)  # how to operate directly on the data\n",
    "\n",
    "            cnt = io.convert_mushu_data(data, marker, sfreq, ch_names)\n",
    "            mr_cnt = io.convert_mushu_data(data3, marker, sfreq, ch_names)\n",
    "            cwl_cnt = io.convert_mushu_data(data6, marker, sfreq, ch_names)\n",
    "\n",
    "            # f_cnt, rt_zi_bp = proc.lfilter(cnt, rt_b_bp, rt_a_bp, zi=rt_zi_bp)  # real-time data preprocessing...\n",
    "\n",
    "            # plotting...\n",
    "            sy1.extend(cnt.data[:,channel_to_plot])  # to visualize/plot -- s1 and s2 are deque's\n",
    "            sy2.extend(mr_cnt.data[:,channel_to_plot])\n",
    "            sy3.extend(cwl_cnt.data[:,channel_to_plot])\n",
    "\n",
    "\n",
    "            l1.set_ydata(sy1)\n",
    "            l2.set_ydata(sy2)\n",
    "            l3.set_ydata(sy3)\n",
    "            msy1=np.mean(sy1)\n",
    "            msy2=np.mean(sy2)\n",
    "            msy3=np.mean(sy3)\n",
    "            ah1.set_ylim(-5000+msy1, 5000+msy1)\n",
    "            ah2.set_ylim(-250+msy2, 250+msy2)\n",
    "            ah3.set_ylim(-250+msy3, 250+msy3)\n",
    "\n",
    "            fig.canvas.draw()\n",
    "            fig.canvas.flush_events()\n",
    "\n",
    "            # i+=1; fname = '_tmp%03d.png' % i; plt.savefig(fname); fnames.append(fname)\n",
    "\n",
    "            # currently has no purpose\n",
    "            newsamples = cnt.data.shape[0]\n",
    "\n",
    "            # append to ringbuffer, so we can calculate features later on on the last N secs/samples of data.\n",
    "            rb.append(cwl_cnt)\n",
    "\n",
    "            # append it to the big matrix, for saving later on with pickle.\n",
    "            alld.extend(data6)\n",
    "            for m in marker:\n",
    "                allm.append([m[0] + markeroffset, m[1]])\n",
    "            markeroffset += newsamples / float(sfreq) * 1000.\n",
    "\n",
    "\n",
    "\n",
    "            # do the following every 0.1 msec - with with the ringbuffer:\n",
    "            if curTime - markTime > updateTime:\n",
    "                # do Stuff\n",
    "\n",
    "                markTime = curTime\n",
    "                # 1) obtain last 1-second(s)\n",
    "                d = rb.get()\n",
    "\n",
    "\n",
    "\n",
    "                # clear_output(wait=True)  # write some logging information here\n",
    "                # clear_output clear the output of the cell, but if you do that you also remove the figures, it seems\n",
    "                # so don't do it!\n",
    "                str1 = 'Playing Back - time = %f' % (curTime - t0)\n",
    "                str2 = 'Length Markers: %d' % len(allm)\n",
    "                str3 = '%d, %d' % data.shape\n",
    "                #str4 = 'Feature Value: %f' % feature\n",
    "                #str5 = 'Scaled Signal for NF: %f' % signalToSend\n",
    "                #print(str1 + '\\n' + str2 + '\\n' + str3 + '\\n' + str4 + '\\n' + str5)\n",
    "\n",
    "                # print('Length Markers: %d' % len(allm))\n",
    "                # print(data.shape)\n",
    "                th.set_text(str1 + '\\n' + str2 + '\\n' +str3)\n",
    "                #featureth.set_text(str4 + '\\n' + str5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.02004 s\n",
       "File: /home/johan/.conda/envs/rt/lib/python3.6/site-packages/scipy/stats/stats.py\n",
       "Function: pearsonr at line 2940\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  2940                                           def pearsonr(x, y):\n",
       "  2941                                               r\"\"\"\n",
       "  2942                                               Calculate a Pearson correlation coefficient and the p-value for testing\n",
       "  2943                                               non-correlation.\n",
       "  2944                                           \n",
       "  2945                                               The Pearson correlation coefficient measures the linear relationship\n",
       "  2946                                               between two datasets. Strictly speaking, Pearson's correlation requires\n",
       "  2947                                               that each dataset be normally distributed, and not necessarily zero-mean.\n",
       "  2948                                               Like other correlation coefficients, this one varies between -1 and +1\n",
       "  2949                                               with 0 implying no correlation. Correlations of -1 or +1 imply an exact\n",
       "  2950                                               linear relationship. Positive correlations imply that as x increases, so\n",
       "  2951                                               does y. Negative correlations imply that as x increases, y decreases.\n",
       "  2952                                           \n",
       "  2953                                               The p-value roughly indicates the probability of an uncorrelated system\n",
       "  2954                                               producing datasets that have a Pearson correlation at least as extreme\n",
       "  2955                                               as the one computed from these datasets. The p-values are not entirely\n",
       "  2956                                               reliable but are probably reasonable for datasets larger than 500 or so.\n",
       "  2957                                           \n",
       "  2958                                               Parameters\n",
       "  2959                                               ----------\n",
       "  2960                                               x : (N,) array_like\n",
       "  2961                                                   Input\n",
       "  2962                                               y : (N,) array_like\n",
       "  2963                                                   Input\n",
       "  2964                                           \n",
       "  2965                                               Returns\n",
       "  2966                                               -------\n",
       "  2967                                               r : float\n",
       "  2968                                                   Pearson's correlation coefficient\n",
       "  2969                                               p-value : float\n",
       "  2970                                                   2-tailed p-value\n",
       "  2971                                           \n",
       "  2972                                               Notes\n",
       "  2973                                               -----\n",
       "  2974                                           \n",
       "  2975                                               The correlation coefficient is calculated as follows:\n",
       "  2976                                           \n",
       "  2977                                               .. math::\n",
       "  2978                                           \n",
       "  2979                                                   r_{pb} = \\frac{\\sum (x - m_x) (y - m_y)\n",
       "  2980                                                                  }{\\sqrt{\\sum (x - m_x)^2 (y - m_y)^2}}\n",
       "  2981                                           \n",
       "  2982                                               where :math:`m_x` is the mean of the vector :math:`x` and :math:`m_y` is\n",
       "  2983                                               the mean of the vector :math:`y`.\n",
       "  2984                                           \n",
       "  2985                                           \n",
       "  2986                                               References\n",
       "  2987                                               ----------\n",
       "  2988                                               http://www.statsoft.com/textbook/glosp.html#Pearson%20Correlation\n",
       "  2989                                           \n",
       "  2990                                               Examples\n",
       "  2991                                               --------\n",
       "  2992                                               >>> from scipy import stats\n",
       "  2993                                               >>> a = np.array([0, 0, 0, 1, 1, 1, 1])\n",
       "  2994                                               >>> b = np.arange(7)\n",
       "  2995                                               >>> stats.pearsonr(a, b)\n",
       "  2996                                               (0.8660254037844386, 0.011724811003954654)\n",
       "  2997                                           \n",
       "  2998                                               >>> stats.pearsonr([1,2,3,4,5], [5,6,7,8,7])\n",
       "  2999                                               (0.83205029433784372, 0.080509573298498519)\n",
       "  3000                                               \"\"\"\n",
       "  3001                                               # x and y should have same length.\n",
       "  3002        56        922.0     16.5      4.6      x = np.asarray(x)\n",
       "  3003        56        173.0      3.1      0.9      y = np.asarray(y)\n",
       "  3004        56        167.0      3.0      0.8      n = len(x)\n",
       "  3005        56       5527.0     98.7     27.6      mx = x.mean()\n",
       "  3006        56       2042.0     36.5     10.2      my = y.mean()\n",
       "  3007        56       1682.0     30.0      8.4      xm, ym = x - mx, y - my\n",
       "  3008        56        786.0     14.0      3.9      r_num = np.add.reduce(xm * ym)\n",
       "  3009        56       4946.0     88.3     24.7      r_den = np.sqrt(_sum_of_squares(xm) * _sum_of_squares(ym))\n",
       "  3010        56        116.0      2.1      0.6      r = r_num / r_den\n",
       "  3011                                           \n",
       "  3012                                               # Presumably, if abs(r) > 1, then it is only some small artifact of\n",
       "  3013                                               # floating point arithmetic.\n",
       "  3014        56        351.0      6.3      1.8      r = max(min(r, 1.0), -1.0)\n",
       "  3015        56         85.0      1.5      0.4      df = n - 2\n",
       "  3016        56        161.0      2.9      0.8      if abs(r) == 1.0:\n",
       "  3017                                                   prob = 0.0\n",
       "  3018                                               else:\n",
       "  3019        56        377.0      6.7      1.9          t_squared = r**2 * (df / ((1.0 - r) * (1.0 + r)))\n",
       "  3020        56       2610.0     46.6     13.0          prob = _betai(0.5*df, 0.5, df/(df+t_squared))\n",
       "  3021                                           \n",
       "  3022        56         95.0      1.7      0.5      return r, prob\n",
       "\n",
       "Total time: 0.002693 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: handle at line 43\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    43                                               def handle(self, data):\n",
       "    44      2450       2693.0      1.1    100.0          return(data)\n",
       "\n",
       "Total time: 0.223176 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: handle at line 66\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    66                                               def handle(self, data):\n",
       "    67                                                   # do all kinds of stuff specific to this filter\n",
       "    68                                                   \n",
       "    69                                                   \n",
       "    70       490     218175.0    445.3     97.8          data, self.zi = signal.lfilter(self.b, self.a, data, zi=self.zi, axis=0)\n",
       "    71                                                   \n",
       "    72       490       5001.0     10.2      2.2          return self.rtfilter.handle(data)\n",
       "\n",
       "Total time: 0.330897 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: handle at line 94\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    94                                               def handle(self, data):\n",
       "    95                                                   # do all kinds of stuff specific to this filter\n",
       "    96                                                   \n",
       "    97                                                   \n",
       "    98       490     326080.0    665.5     98.5          data, self.zi = signal.lfilter(self.b, self.a, data, zi=self.zi, axis=0)\n",
       "    99                                                   \n",
       "   100       490       4817.0      9.8      1.5          return self.rtfilter.handle(data)\n",
       "\n",
       "Total time: 0.356176 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: handle at line 181\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   181                                               def handle(self, datain):\n",
       "   182                                                   ''' actually do the mr correction - gather MR segments into a little list, and if certain conditions are met, \n",
       "   183                                                       do a subtraction to get clean mr data. very easy template-based subtraction.\n",
       "   184                                                       In case of severe MR artifact changes (taken over all channels), this can also reset/change the buffer on the fly.\n",
       "   185                                                       This is handy for not having to stop the acquisition!\n",
       "   186                                                   '''\n",
       "   187                                                   \n",
       "   188                                                   \n",
       "   189       490       1848.0      3.8      0.5          if not self.first_data_sent:\n",
       "   190                                                   \n",
       "   191         1          4.0      4.0      0.0              self.first_data_sent = True\n",
       "   192         1          7.0      7.0      0.0              _, self.nbchans = datain.shape\n",
       "   193         1         14.0     14.0      0.0              self.prcorr_downsampling_factor = round((self.trsamples * self.nbchans) /  self.ncorrvalues)\n",
       "   194                                                       \n",
       "   195                                                   \n",
       "   196       490       2060.0      4.2      0.6          nbpoints = datain.shape[0] # this changes all the time...\n",
       "   197       490       1887.0      3.9      0.5          prcorr_downsampling_factor = self.prcorr_downsampling_factor\n",
       "   198       490       1633.0      3.3      0.5          trsamples = self.trsamples\n",
       "   199                                                   \n",
       "   200                                                   # filter it - butterworth style:\n",
       "   201       490       1558.0      3.2      0.4          if self.applyHPF:\n",
       "   202                                                       # we consider the incoming data - but only filtered\n",
       "   203                                                       \n",
       "   204                                                       if not self.zi_initiated:\n",
       "   205                                                           self.hpzi = np.tile(self.hpzi, (datain.shape[1], 1)).T\n",
       "   206                                                           self.zi_initiated = True\n",
       "   207                                                       \n",
       "   208                                                       # pdb.set_trace()\n",
       "   209                                                       #data, self.hpzi = signal.lfilter(self.hpb, self.hpa, datain, zi=self.hpzi, axis=0)\n",
       "   210                                                       data, self.hpzi = signal.lfilter(self.hpb, self.hpa, datain, zi=self.hpzi, axis=0)\n",
       "   211                                                       #data = signal.filtfilt(self.hpb, self.hpa, datain, axis=0)\n",
       "   212                                                   else:\n",
       "   213       490       1448.0      3.0      0.4              data = datain\n",
       "   214                                           \n",
       "   215                                           \n",
       "   216                                                   \n",
       "   217                                                   \n",
       "   218                                                   \n",
       "   219                                                   # create the buffer without having to do it in __init__\n",
       "   220                                                   # so we can know the nbchan \n",
       "   221       490       1803.0      3.7      0.5          if not self.buff_initialized:\n",
       "   222         1          5.0      5.0      0.0              self.nbchan = data.shape[1]\n",
       "   223         1       1454.0   1454.0      0.4              self.buff = np.zeros((self.trsamples, self.nbchan), dtype='float')\n",
       "   224         1          4.0      4.0      0.0              self.buff_i = 0\n",
       "   225         1          3.0      3.0      0.0              self.buff_initialized = True\n",
       "   226                                                       \n",
       "   227                                                       \n",
       "   228                                                       \n",
       "   229                                           \n",
       "   230                                           \n",
       "   231                                                       \n",
       "   232                                                   \n",
       "   233                                                   \n",
       "   234                                                   # finish the current template/buffer, or do the work\n",
       "   235                                                   # to consider a new MR template?\n",
       "   236       490       2343.0      4.8      0.7          if self.buff_i + nbpoints < self.trsamples:\n",
       "   237                                                       \n",
       "   238                                                       # store data in buffer\n",
       "   239       449      20019.0     44.6      5.6              self.buff[self.buff_i:self.buff_i+nbpoints,:] = data\n",
       "   240                                                       \n",
       "   241                                                       \n",
       "   242                                                       # can we correct it? -- then this is >0\n",
       "   243       449       2036.0      4.5      0.6              if self.selected >= 0:\n",
       "   244                                                           # look up what kind of MR we need to remove from library\n",
       "   245       357       1487.0      4.2      0.4                  t_d = self.mrt[self.selected]\n",
       "   246                                                       \n",
       "   247                                                           #pdb.set_trace()\n",
       "   248       357      25611.0     71.7      7.2                  corr_data = datain - t_d[self.buff_i:(self.buff_i+nbpoints),:]\n",
       "   249                                                       \n",
       "   250                                                       else:\n",
       "   251        92        319.0      3.5      0.1                  corr_data = datain\n",
       "   252                                                       \n",
       "   253       449       2196.0      4.9      0.6              self.buff_i += nbpoints\n",
       "   254       449       3339.0      7.4      0.9              return self.rtfilter.handle(corr_data)\n",
       "   255                                                       \n",
       "   256                                                       \n",
       "   257                                                   else:\n",
       "   258                                           \n",
       "   259                                                       #print(self.mrN)\n",
       "   260                                                       #print(self.mrLastUsed)\n",
       "   261                                                       \n",
       "   262        41        160.0      3.9      0.0              prev_selected = self.selected\n",
       "   263                                                       \n",
       "   264                                                       # complete buffer\n",
       "   265        41       1521.0     37.1      0.4              self.buff[self.buff_i:self.trsamples,:] = data[0:(self.trsamples-self.buff_i),:]\n",
       "   266                                                       \n",
       "   267                                                       # temporary buffer to be used for later...\n",
       "   268        41       4413.0    107.6      1.2              tbuff = data[(self.trsamples-self.buff_i):nbpoints,:]\n",
       "   269                                                       \n",
       "   270                                                       \n",
       "   271                                                       \n",
       "   272                                                       # this will happen also with the followiung code, anyway.\n",
       "   273                                                       #            # is there some info yet about MR artifacts? if not - create..\n",
       "   274                                                       #            if len(self.mrt) == 0:\n",
       "   275                                                       #                self.mrt.append(np.zeros((self.trsamples, self.nbchan), dtype='float'))\n",
       "   276                                                       #                self.mrN.append(1)\n",
       "   277                                                       #                self.mrLastUsed.append(1)\n",
       "   278                                                       #\n",
       "   279                                                       #                # and store buff in that, too                \n",
       "   280                                                       #                self.mrt[-1] = self.buff\n",
       "   281                                           \n",
       "   282                                           \n",
       "   283                                                       # calculate all of the correlations with the rest of them\n",
       "   284                                                       # and how many are in there, too...\n",
       "   285                                                       #corrs, N = zip(*[(pearsonr(self.buff.flatten(), m.flatten()), self.mrN(i_N)) for i_N, m in enumerate(self.mrt)])\n",
       "   286                                                       #if len(self.mrN)>0:\n",
       "   287                                                       #    if self.mrN[0]>5:\n",
       "   288                                                       #ipdb.set_trace()\n",
       "   289                                                       \n",
       "   290        41     110470.0   2694.4     31.0              corrs = [pearsonr(self.buff.flatten()[0:trsamples:prcorr_downsampling_factor], m.flatten()[0:trsamples:prcorr_downsampling_factor])[0] for m in self.mrt]\n",
       "   291                                                       #print(corrs)\n",
       "   292                                           \n",
       "   293                                                       # update the library -- actions\n",
       "   294        41        501.0     12.2      0.1              if any([corr > self.corr_thr for corr in corrs]):\n",
       "   295                                           \n",
       "   296                                                           # select what our current marked library of templates is:\n",
       "   297        36        248.0      6.9      0.1                  i_maxcorr = corrs.index(max(corrs))\n",
       "   298                                               \n",
       "   299                                                           # add it to the select library:\n",
       "   300                                                           # weighting 1 : restore original values\n",
       "   301        36      21588.0    599.7      6.1                  self.mrt[i_maxcorr] *= float(self.mrN[i_maxcorr])\n",
       "   302                                               \n",
       "   303                                                           # weighting 2 : increase the N\n",
       "   304        36        299.0      8.3      0.1                  self.mrN[i_maxcorr] += 1.0\n",
       "   305                                               \n",
       "   306                                                           # weighting 3 : divide with the new N\n",
       "   307        36      32351.0    898.6      9.1                  self.mrt[i_maxcorr] /= self.mrN[i_maxcorr]\n",
       "   308                                               \n",
       "   309                                                           # then add the new buff; weighted:\n",
       "   310        36      70012.0   1944.8     19.7                  self.mrt[i_maxcorr] += copy.copy(self.buff) / self.mrN[i_maxcorr]\n",
       "   311                                                           \n",
       "   312                                                           \n",
       "   313                                                           # HERE -- I should arrange that lastused is taken care of... : i_maxcorr\n",
       "   314                                                           # add 1 to all last N, but set the one of self.selected to 1 (i.e., this is the last used one)\n",
       "   315        36        721.0     20.0      0.2                  self.mrLastUsed = [*map(lambda x: x+1, self.mrLastUsed)]\n",
       "   316        36        134.0      3.7      0.0                  self.mrLastUsed[i_maxcorr] = 1\n",
       "   317                                               \n",
       "   318                                                       else:\n",
       "   319                                                           \n",
       "   320                                                           # HERE -- taking care : the last one!\n",
       "   321                                               \n",
       "   322                                                           # so - the buffer is completely NEW -- so let's try making a new template, then - + store it inside\n",
       "   323         5        930.0    186.0      0.3                  self.mrt.append(np.zeros((self.trsamples, self.nbchan), dtype='float'))\n",
       "   324                                                           #self.mrt.append(self.buff)\n",
       "   325         5         35.0      7.0      0.0                  self.mrN.append(1)\n",
       "   326         5         17.0      3.4      0.0                  self.mrLastUsed.append(0)\n",
       "   327                                                           # and store it, too\n",
       "   328         5      14101.0   2820.2      4.0                  self.mrt[-1] = copy.copy(self.buff) # HERE -- we add the buffer!!\n",
       "   329         5         25.0      5.0      0.0                  corrs.append(0)  # also grow corrs - for later:\n",
       "   330                                           \n",
       "   331                                           \n",
       "   332                                                           # HERE -- I should arrange that lastused is taken care of... : i_maxcorr\n",
       "   333                                                           # add 1 to all last N, but set the one of self.selected to 1 (i.e., this is the last used one)\n",
       "   334         5         67.0     13.4      0.0                  self.mrLastUsed = [*map(lambda x: x+1, self.mrLastUsed)]\n",
       "   335         5         16.0      3.2      0.0                  self.mrLastUsed[-1] = 1\n",
       "   336                                           \n",
       "   337                                           \n",
       "   338                                                       # figure out which one we're going to select now: -- or NOT...\n",
       "   339        41        126.0      3.1      0.0              keepi=[]\n",
       "   340        41        123.0      3.0      0.0              keepcorr=[]\n",
       "   341        41        127.0      3.1      0.0              keepN=[]\n",
       "   342       102        566.0      5.5      0.2              for i, (c, N) in enumerate(zip(corrs, self.mrN)):\n",
       "   343        61        322.0      5.3      0.1                  if N > self.N_thr and c > self.corr_thr:\n",
       "   344        32        149.0      4.7      0.0                      keepi.append(i)\n",
       "   345        32        104.0      3.2      0.0                      keepcorr.append(i)\n",
       "   346        32        132.0      4.1      0.0                      keepN.append(i)\n",
       "   347                                                        \n",
       "   348                                                       # do we select anything now?\n",
       "   349        41        156.0      3.8      0.0              if len(keepi) > 0:\n",
       "   350                                                   \n",
       "   351                                                           #print('----')\n",
       "   352                                                           #print(keepi)\n",
       "   353                                                           #pdb.set_trace()\n",
       "   354                                                           # so these all adhere to the thresholds -- now figure out which one to choose for artifact correction -- and update 'self.selected'\n",
       "   355        32        268.0      8.4      0.1                  self.selected = keepi[keepcorr.index(max(keepcorr))]\n",
       "   356                                                           #print('selected: %d' % self.selected)\n",
       "   357                                           \n",
       "   358                                                       else:\n",
       "   359         9         27.0      3.0      0.0                  self.selected = -1                \n",
       "   360                                           \n",
       "   361                                                       \n",
       "   362                                                       # correct data -- part I -- from the old buffer\n",
       "   363                                                       # correct the prev buffer with prev_selected\n",
       "   364        41        122.0      3.0      0.0              if prev_selected >= 0:\n",
       "   365                                                       \n",
       "   366        31        106.0      3.4      0.0                  t_d = self.mrt[prev_selected]\n",
       "   367                                                       \n",
       "   368        31        296.0      9.5      0.1                  tosubtract1 = t_d[self.buff_i:self.buff_i+self.trsamples,:]\n",
       "   369                                                       else:\n",
       "   370        10        295.0     29.5      0.1                  tosubtract1 = np.zeros((self.trsamples-self.buff_i, self.nbchan), dtype='float')\n",
       "   371                                                   \n",
       "   372        41        134.0      3.3      0.0              if self.selected >= 0:\n",
       "   373                                                           \n",
       "   374        32        106.0      3.3      0.0                  t_d = self.mrt[self.selected]\n",
       "   375                                                           \n",
       "   376        32        194.0      6.1      0.1                  tosubtract2 = t_d[0:(-1*(self.trsamples-self.buff_i)+nbpoints),:]\n",
       "   377                                                       else:\n",
       "   378         9        132.0     14.7      0.0                  tosubtract2 = np.zeros((-1*(self.trsamples-self.buff_i)+nbpoints, self.nbchan), dtype='float')\n",
       "   379                                                           # correct data -- part II -- from the new buffer\n",
       "   380                                                           # correct the current buffer with NEW selected\n",
       "   381                                                           \n",
       "   382        41       2060.0     50.2      0.6              tosubtract_full = np.concatenate((tosubtract1, tosubtract2))\n",
       "   383                                                       # get rid of the very old stuff in library\n",
       "   384                                                       \n",
       "   385                                                       \n",
       "   386                                                       # update the buffer:\n",
       "   387                                                       #pdb.set_trace()\n",
       "   388        41      14139.0    344.9      4.0              self.buff[:,:]=0\n",
       "   389        41        241.0      5.9      0.1              self.buff_i = -1*(self.trsamples-self.buff_i)+nbpoints\n",
       "   390        41       1733.0     42.3      0.5              self.buff[0:self.buff_i,:] = tbuff\n",
       "   391                                                       \n",
       "   392                                           \n",
       "   393                                                       \n",
       "   394                                                       # obselete code:\n",
       "   395                                                       # corr_data = data - tosubtract_full\n",
       "   396                                           \n",
       "   397                                           \n",
       "   398                                           \n",
       "   399                                                   #first throw things away...\n",
       "   400                                                   #    pdb.set_trace()\n",
       "   401                                                   # forget the old stuffm after self.forget times of not-being-used\n",
       "   402        41        446.0     10.9      0.1          mark=[i for i, lastused in enumerate(self.mrLastUsed) if lastused > self.forget]\n",
       "   403                                                   \n",
       "   404                                                   # forget them...\n",
       "   405        45        366.0      8.1      0.1          for popi in reversed(mark): #[::-1]:\n",
       "   406         4         32.0      8.0      0.0              self.mrt.pop(popi)\n",
       "   407         4         15.0      3.8      0.0              self.mrN.pop(popi)\n",
       "   408         4         15.0      3.8      0.0              self.mrLastUsed.pop(popi)  \n",
       "   409                                                   # data=copy.copy(datain) -- making sure that our selected remains pointed\n",
       "   410                                                   # to the right one\n",
       "   411        41        158.0      3.9      0.0          if len(mark)>0 and self.selected>=0:\n",
       "   412                                                       #print('----')\n",
       "   413                                                       #print(self.selected)\n",
       "   414                                                       self.selected -= sum([self.selected > i for i in mark])\n",
       "   415                                                       #print(self.selected)\n",
       "   416                                                       #print(mark)\n",
       "   417                                                       \n",
       "   418                                                   # handle return...\n",
       "   419        41       4799.0    117.0      1.3          return self.rtfilter.handle(datain - tosubtract_full)\n",
       "\n",
       "Total time: 1.76636 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: handle at line 654\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   654                                               def handle(self, datain):\n",
       "   655                                                   \n",
       "   656                                                   \n",
       "   657                                                   # filter it - butterworth style:\n",
       "   658       490       1299.0      2.7      0.1          if self.applyHPF:\n",
       "   659                                                       # we consider the incoming data - but only filtered\n",
       "   660                                                       \n",
       "   661                                                       if not self.zi_initiated:\n",
       "   662                                                           self.hpzi = np.tile(self.hpzi, (datain.shape[1], 1)).T\n",
       "   663                                                           self.zi_initiated = True\n",
       "   664                                                       \n",
       "   665                                                       # pdb.set_trace()\n",
       "   666                                                       #data, self.hpzi = signal.lfilter(self.hpb, self.hpa, datain, zi=self.hpzi, axis=0)\n",
       "   667                                                       data, self.hpzi = signal.lfilter(self.hpb, self.hpa, datain, zi=self.hpzi, axis=0)\n",
       "   668                                                       #data = signal.filtfilt(self.hpb, self.hpa, datain, axis=0)\n",
       "   669                                                   else:\n",
       "   670       490       1112.0      2.3      0.1              data = datain\n",
       "   671                                                   \n",
       "   672                                                   \n",
       "   673                                                   # first to do timeshifting stuff --> then worry about allocation into different subregions...\n",
       "   674       490     626466.0   1278.5     35.5          ddata, dy, dXn = self._handle_delays(data)\n",
       "   675                                                   \n",
       "   676                                                   # we HAVE called this -- but we need a second buffer here. - this function has reduced functionality than the one above:\n",
       "   677       490       1412.0      2.9      0.1          if self.applyHPF:\n",
       "   678                                                       ddata = self._return_delayed_data(datain)\n",
       "   679                                                       # ddy = ddata[:,self.ichs]\n",
       "   680                                                   \n",
       "   681                                                   \n",
       "   682       490       1825.0      3.7      0.1          s=self.s  # current sample\n",
       "   683       490       1281.0      2.6      0.1          N=data.shape[0]\n",
       "   684       490       1121.0      2.3      0.1          nwin=self.nwin\n",
       "   685                                                   \n",
       "   686                                                   #cleaned_chs=[]\n",
       "   687                                                   # cleaned_data = self._return_delayed_data()\n",
       "   688                                                   # ipdb.set_trace()\n",
       "   689       490        965.0      2.0      0.1          cleaned = []\n",
       "   690      1470       5955.0      4.1      0.3          for i in range(len(self.taperlist)):\n",
       "   691       980      18765.0     19.1      1.1              cleaned.append(data[:,0:len(self.ichs)].copy())\n",
       "   692                                                       \n",
       "   693       490       1023.0      2.1      0.1          to_subtract = []\n",
       "   694      1470       4308.0      2.9      0.2          for i in range(len(self.taperlist)):\n",
       "   695       980      12892.0     13.2      0.7              to_subtract.append(data[:,0:len(self.ichs)].copy())\n",
       "   696                                           \n",
       "   697                                           \n",
       "   698       490       1094.0      2.2      0.1          if self.DEBUG:\n",
       "   699                                                       sumcheck = []\n",
       "   700                                                       for i in range(len(self.taperlist)):\n",
       "   701                                                           sumcheck.append(data[:,0:len(self.ichs)].copy())\n",
       "   702                                                   \n",
       "   703                                           \n",
       "   704                                                   # cwls = data[:,self.icws]  # better do it here - breakdown into cwls and signals\n",
       "   705                                                   # signals = data[:,self.ichs]  # when we return data, we replace some cols from data with corrected signals\n",
       "   706                                                   \n",
       "   707                                                   # go through the list as per our notes -- only COLLECT here, and start new estimations where necessary.\n",
       "   708      1470       8965.0      6.1      0.5          for itaper, tli in enumerate(self.taperlist):\n",
       "   709                                                       \n",
       "   710       980       1684.0      1.7      0.1              finished=False\n",
       "   711       980       1675.0      1.7      0.1              cur_s = s\n",
       "   712                                                       \n",
       "   713                                                       \n",
       "   714                                                       # if itaper == 1 and tli['s'] > 9000 and cur_s > 17000:\n",
       "   715                                                       #     ipdb.set_trace()\n",
       "   716                                                       # re-do this -- figure out DATA indices, and X indices\n",
       "   717                                                       # then make a list of that\n",
       "   718                                                       # then just go through the list\n",
       "   719                                                       # otherwise I cannot follow it anymore\n",
       "   720                                                       \n",
       "   721      1985       4746.0      2.4      0.3              while not finished:\n",
       "   722                                                           \n",
       "   723      1005       2657.0      2.6      0.2                  if cur_s >= tli['s']:\n",
       "   724                                                               # ipdb.set_trace()\n",
       "   725                                                               # check for beta queue                \n",
       "   726       989       2245.0      2.3      0.1                      if s+N > tli['s'] + nwin:\n",
       "   727        25         50.0      2.0      0.0                          curN = tli['s'] + nwin - cur_s\n",
       "   728                                                               else:\n",
       "   729       964       1856.0      1.9      0.1                          curN = s + N - cur_s\n",
       "   730                                                           \n",
       "   731                                                                   \n",
       "   732       989       1917.0      1.9      0.1                      bXn = cur_s - tli['s']  # see notes\n",
       "   733                                                                   \n",
       "   734       989       1720.0      1.7      0.1                      eXn = bXn + curN   # see notes\n",
       "   735                                                               \n",
       "   736       989       3793.0      3.8      0.2                      Xindices=range(bXn,eXn)  # taking care of neg/positive...\n",
       "   737                                                               \n",
       "   738       989       1874.0      1.9      0.1                      bd = cur_s - s   # see notes\n",
       "   739       989       1764.0      1.8      0.1                      ed = bd + curN   # see notes\n",
       "   740                                                               \n",
       "   741       989       2317.0      2.3      0.1                      dindices=range(bd,ed)\n",
       "   742                                                               # put y and X where they belong\n",
       "   743                                                               #ipdb.set_trace()\n",
       "   744                                                               \n",
       "   745                                                               #pd = part of delay(ed)...\n",
       "   746                                                               #if not self.applyHRF:\n",
       "   747       989     458515.0    463.6     26.0                      pdXn, pdy = self._handle_partition_and_hanning(dy, dXn, [bd, ed], [bXn, eXn])\n",
       "   748                                                               #else:\n",
       "   749                                                               #    pdXn, pdy = self._handle_partition_and_hanning(dy, dXn, dindices, Xindices)\n",
       "   750                                           \n",
       "   751       989     215943.0    218.3     12.2                      pdY = np.dot(pdXn, tli['b'])\n",
       "   752       989      30011.0     30.3      1.7                      pde = pdy-pdY\n",
       "   753                                           \n",
       "   754       989     109639.0    110.9      6.2                      tli['Xn'][Xindices,:] = pdXn\n",
       "   755       989      45392.0     45.9      2.6                      tli['y'][Xindices,:] = pdy\n",
       "   756       989      37825.0     38.2      2.1                      tli['Y'][Xindices,:] = pdY\n",
       "   757                                                           \n",
       "   758       989      31002.0     31.3      1.8                      cleaned[itaper][dindices,:] = pde  # assign the data\n",
       "   759       989      31574.0     31.9      1.8                      to_subtract[itaper][dindices,:] = pdY\n",
       "   760       989       2661.0      2.7      0.2                      if self.DEBUG:\n",
       "   761                                                                   sumcheck[itaper][dindices,:] = self.hwy[Xindices,:]\n",
       "   762                                                   \n",
       "   763      1005       2715.0      2.7      0.2                  if tli['s'] + nwin > s + N:\n",
       "   764       980       1633.0      1.7      0.1                      finished=True\n",
       "   765       980       1630.0      1.7      0.1                      gotoNextWindow=False\n",
       "   766        25         52.0      2.1      0.0                  elif tli['s'] + nwin == s + N:\n",
       "   767                                                               finished=True\n",
       "   768                                                               gotoNextWindow=True\n",
       "   769                                                           else:\n",
       "   770        25         40.0      1.6      0.0                      finished=False\n",
       "   771        25         39.0      1.6      0.0                      gotoNextWindow=True\n",
       "   772                                                                   \n",
       "   773                                                                   \n",
       "   774      1005       1668.0      1.7      0.1                  if gotoNextWindow:       \n",
       "   775                                                            \n",
       "   776                                                               # ipdb.set_trace()\n",
       "   777                                                               \n",
       "   778                                                               # 'init' a new one, too. associate our most current beta's to that\n",
       "   779        25       1285.0     51.4      0.1                      self._check_switch_betas()  # figure out / upkeep on beta estimations - check the queue. -- kalman should be implemented here?\n",
       "   780                                                               # 'send off' the current window for estimation\n",
       "   781        25       2134.0     85.4      0.1                      self._estimate_betas(tli)\n",
       "   782                                           \n",
       "   783                                                               # change tli:                    \n",
       "   784        25         75.0      3.0      0.0                      tli['b'] = self.currentbetas   # assign the latest one(s) -- or the Kalman estimated ones\n",
       "   785                                           \n",
       "   786        25         76.0      3.0      0.0                      tli['s'] += nwin-1\n",
       "   787        25         46.0      1.8      0.0                      cur_s = tli['s']\n",
       "   788                                                               # tli['Xn'] =np.zeros((self.nwin, len(self.icws) * (self.sfuture+self.spast+1)))\n",
       "   789                                                               # you completed a window --> adjust s and N\n",
       "   790                                                               \n",
       "   791                                           \n",
       "   792                                                               #ipdb.set_trace()\n",
       "   793                                                               \n",
       "   794                                                                   \n",
       "   795                                                               \n",
       "   796                                                               # HERE - we figure out whether we 'set' the beta's - or not\n",
       "   797                                                               # if they're set -- then, we we associate the latest set of beta's to the current window\n",
       "   798                                                               # we also will not anymore check whether beta's are estimated\n",
       "   799                                                               # instead, we fill the list of 'current' beta's with 0. That will produce 0, too.\n",
       "   800                                                               # we also need to pass the current beta's...\n",
       "   801                                                               \n",
       "   802                                                               # if we're here, then we need to estimate something!\n",
       "   803                                                               # send (complete) window to estimator\n",
       "   804                                                               # ipdb.set_trace()\n",
       "   805                                                               # self._check_switch_betas()\n",
       "   806                                           \n",
       "   807                                                   #if s > 17000:\n",
       "   808                                                   #    ipdb.set_trace()\n",
       "   809                                           \n",
       "   810                                                   # sum it all up\n",
       "   811       490       1432.0      2.9      0.1          if self.taperfactor == 1:\n",
       "   812                                                       # cleaned_channels = sum(cleaned)  # summate over the tapers (we have 2 tapers with taperfactor == 1, usually.)\n",
       "   813       490      15165.0     30.9      0.9              cwlsignals_to_subtract = sum(to_subtract)\n",
       "   814       490       1202.0      2.5      0.1              if self.DEBUG:\n",
       "   815                                                           checked_sumcheck = sum(sumcheck)\n",
       "   816                                                   else:\n",
       "   817                                                       # cleaned_channels = sum(cleaned) / float(self.taperfactor)\n",
       "   818                                                       cwlsignals_to_subtract = sum(to_subtract) / float(self.taperfactor)\n",
       "   819                                                       if self.DEBUG:\n",
       "   820                                                           checked_sumcheck = sum(sumcheck) / float(self.taperfactor)\n",
       "   821                                           \n",
       "   822                                                   \n",
       "   823                                                   #if s > 17000:\n",
       "   824                                                   #    ipdb.set_trace()\n",
       "   825                                           \n",
       "   826                                                   # set the corrected channels to the channels that we just corrected!\n",
       "   827       490      51016.0    104.1      2.9          ddata[:,self.ichs] = ddata[:,self.ichs] - cwlsignals_to_subtract\n",
       "   828       490       1154.0      2.4      0.1          if self.DEBUG:\n",
       "   829                                                       ddata[:,self.ichs] = checked_sumcheck  # check whether the weights are always == 1!\n",
       "   830       490       2306.0      4.7      0.1          self.s += data.shape[0]   \n",
       "   831       490       3352.0      6.8      0.2          return self.rtfilter.handle(ddata)\n",
       "\n",
       "Total time: 0.4389 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: _handle_partition_and_hanning at line 835\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   835                                               def _handle_partition_and_hanning(self, dy, dXn, dindices, Xindices):\n",
       "   836                                                   \n",
       "   837                                                   \"\"\" So this should be simple enough \n",
       "   838                                                       - use dincides on data(selecting a part of it)\n",
       "   839                                                       - then apply hanning window following Xindices on both dXn and dy\n",
       "   840                                                       - and return result?\n",
       "   841                                                   \"\"\"\n",
       "   842                                                   \n",
       "   843       989       1438.0      1.5      0.3          bd, ed = dindices\n",
       "   844       989        837.0      0.8      0.2          bXn, eXn = Xindices\n",
       "   845                                                   \n",
       "   846                                                   #if any([x < 0 for x in [bd, ed, bXn, eXn]]):\n",
       "   847                                                   #    ipdb.set_trace()\n",
       "   848                                                   \n",
       "   849       989       4391.0      4.4      1.0          hanning_for_y = self.hwy[bXn:eXn,:]\n",
       "   850                                                   \n",
       "   851       989      86039.0     87.0     19.6          pdy = dy[bd:ed] * hanning_for_y\n",
       "   852                                           \n",
       "   853       989       3522.0      3.6      0.8          hanning_for_dXn = self.hwts[bXn:eXn,:]\n",
       "   854                                                   \n",
       "   855       989     341074.0    344.9     77.7          pdXn = dXn[bd:ed,:] * hanning_for_dXn\n",
       "   856                                                   \n",
       "   857       989       1599.0      1.6      0.4          return pdXn, pdy\n",
       "\n",
       "Total time: 0.494833 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: _handle_delays at line 864\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   864                                               def _handle_delays(self, data):\n",
       "   865                                                   \"\"\" This function return in delayed form: \n",
       "   866                                                           (a) the full data (because we need it)\n",
       "   867                                                           (b) the data specified by the cwl's (i.e., y)\n",
       "   868                                                       reurns in time-expanded form:\n",
       "   869                                                           (c) the Xn - with the temporal expansion(s)\n",
       "   870                                                   \"\"\"\n",
       "   871                                                   \n",
       "   872                                                   \n",
       "   873                                                   # first - buffer it\n",
       "   874       490      46457.0     94.8      9.4          self._buffer_data(data, self.sfuture + self.spast)\n",
       "   875                                                   \n",
       "   876                                                   \n",
       "   877                                                   # then get the data (and make a copy of it?)\n",
       "   878       490      27915.0     57.0      5.6          tmpdata = copy.deepcopy(self._buffereddata)\n",
       "   879                                                   \n",
       "   880       490      29604.0     60.4      6.0          tmpdata2 = tmpdata[:, self.icws]  # remove the need for advanced indexing, so we can just slice it:\n",
       "   881                                                   \n",
       "   882                                                   \n",
       "   883                                                   # then: construct the Xn\n",
       "   884       490      15829.0     32.3      3.2          Xn = np.zeros((data.shape[0], len(self.icws) * (self.sfuture+self.spast+1)))\n",
       "   885                                           \n",
       "   886                                                   # here is the magic where things get 'delayed' - the stuff we put in...\n",
       "   887     25480      58814.0      2.3     11.9          for i, d in enumerate(self.delayvec):\n",
       "   888                                                       \n",
       "   889                                                       # this is now actually correct!\n",
       "   890     24990      55140.0      2.2     11.1              startind = tmpdata.shape[0]-len(self.delayvec)+i-data.shape[0]+1\n",
       "   891     24990      30318.0      1.2      6.1              stopind = startind + data.shape[0]\n",
       "   892                                                       \n",
       "   893                                                       #try:\n",
       "   894                                                           \n",
       "   895                                                           \n",
       "   896                                                           #tmpdata2=tmpdata[range(startind,stopind), :]\n",
       "   897     24990     185340.0      7.4     37.5              Xn[:, i*len(self.icws):(i+1)*len(self.icws)] = tmpdata2[startind:stopind, :]\n",
       "   898                                                       #except:\n",
       "   899                                           \n",
       "   900                                                   \n",
       "   901                                                   \n",
       "   902                                                   # Xn is done: now deal with y\n",
       "   903                                                   # normal_range:\n",
       "   904       490       5231.0     10.7      1.1          startind = tmpdata.shape[0] - self.zerodelayindex-data.shape[0]\n",
       "   905       490       1173.0      2.4      0.2          stopind = startind + data.shape[0]\n",
       "   906                                                   \n",
       "   907       490       1877.0      3.8      0.4          alldata = tmpdata[startind:stopind,:]\n",
       "   908                                                   \n",
       "   909       490      35981.0     73.4      7.3          y=tmpdata[startind:stopind,self.ichs]\n",
       "   910                                                   \n",
       "   911                                                   \n",
       "   912       490       1154.0      2.4      0.2          return alldata, y, Xn\n",
       "\n",
       "Total time: 0.001882 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: _estimate_betas at line 997\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   997                                               def _estimate_betas(self, tli):\n",
       "   998                                                   \"\"\" This function will actually Estimate beta's, from a 'completed' window l\n",
       "   999                                                   \"\"\"\n",
       "  1000                                                   # first it will make a copy that we're going to use\n",
       "  1001                                                   \n",
       "  1002                                                   # then it will make a Process that will do the actual estimation\n",
       "  1003                                                   \n",
       "  1004                                                   #ipdb.set_trace()\n",
       "  1005        25         26.0      1.0      1.4          X = tli['Xn']\n",
       "  1006        25         23.0      0.9      1.2          y = tli['y']\n",
       "  1007        25         22.0      0.9      1.2          Yprev = tli['Y']\n",
       "  1008                                                   \n",
       "  1009                                           \n",
       "  1010        25         23.0      0.9      1.2          prev_betas = tli['b']\n",
       "  1011                                           \n",
       "  1012                                                   # contains 6 regressors; taken with different time delays\n",
       "  1013                                                   # so the beta's are per cwl-per-delay the fit to y.\n",
       "  1014                                                   # ipdb.set_trace()\n",
       "  1015                                                   #p=multiprocessing.Process(target=estimate_it, args=(X, y, Yprev, self._queue_incoming_betas, prev_betas))\n",
       "  1016                                                   #p.start()\n",
       "  1017                                                   \n",
       "  1018        25       1788.0     71.5     95.0          self._queue_estimate_it.put((X, y, Yprev, prev_betas, self.saveglms))\n",
       "\n",
       "Total time: 0.000993 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: _check_switch_betas at line 1025\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  1025                                               def _check_switch_betas(self):\n",
       "  1026                                                   \"\"\" check the queues -- do upkeep with those outputs, plz...\n",
       "  1027                                                   \"\"\"\n",
       "  1028                                                   # check the queus - if they are full/filled, then change betas\n",
       "  1029                                                   #ipdb.set_trace()\n",
       "  1030        25        406.0     16.2     40.9          if self._can_read_arr_val.value > 0:\n",
       "  1031                                                       \n",
       "  1032        25        309.0     12.4     31.1              betas = np.frombuffer(self._beta_shared_arr).reshape((len(self.icws)*(self.spast+self.sfuture+1),len(self.ichs)))\n",
       "  1033                                                       # betas = self._queue_incoming_betas.get_nowait()\n",
       "  1034                                                       #self._can_read_arr.clear() \n",
       "  1035        25        175.0      7.0     17.6              self._can_read_arr_val.value = -1\n",
       "  1036                                                       # we append em here...\n",
       "  1037        25         52.0      2.1      5.2              self.betas.append(betas)\n",
       "  1038                                           \n",
       "  1039                                                       # simple assignment - or use Kalman or some average..\n",
       "  1040        25         51.0      2.0      5.1              self.currentbetas=self.betas[-1]\n",
       "\n",
       "Total time: 0.039397 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: _buffer_data at line 1078\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  1078                                               def _buffer_data(self, data, nsamples):\n",
       "  1079                                                   \"\"\" since we deal potentially with delayed versions of data - we would need to have a small buffer\n",
       "  1080                                                       which we use to recall stuff from.\n",
       "  1081                                                       It CAN be that the amount of data coming in, is smaller than the desired size of the buffer\n",
       "  1082                                                       so solve that here.\n",
       "  1083                                                       # this will just update the _buffereddata\n",
       "  1084                                                       \n",
       "  1085                                                       THIS works in conjunction with _handle_delay_taper_cwl_channel_selection\n",
       "  1086                                                       To more easily handle the delays there (and select appropriate data)\n",
       "  1087                                                       \n",
       "  1088                                                   \"\"\"\n",
       "  1089                                                   \n",
       "  1090                                                   # ipdb.set_trace()\n",
       "  1091                                                   \n",
       "  1092       490       1631.0      3.3      4.1          if len(self._buffereddata) == 0:\n",
       "  1093         1         16.0     16.0      0.0              self._buffereddata = np.zeros(data.shape)\n",
       "  1094       660       2230.0      3.4      5.7          while self._buffereddata.shape[0] < nsamples+data.shape[0]:\n",
       "  1095       170       6706.0     39.4     17.0              self._buffereddata = np.concatenate((np.zeros(data.shape), self._buffereddata))\n",
       "  1096                                                   \n",
       "  1097       490      24712.0     50.4     62.7          self._buffereddata = np.concatenate((self._buffereddata, data))\n",
       "  1098                                                   \n",
       "  1099       490       1296.0      2.6      3.3          if self._buffereddata.shape[0] + data.shape[0] > nsamples:\n",
       "  1100       490       2806.0      5.7      7.1              self._buffereddata = self._buffereddata[-nsamples-data.shape[0]:,:]\n",
       "\n",
       "Total time: 0.165466 s\n",
       "File: /home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\n",
       "Function: handle at line 1140\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  1140                                               def handle(self, data):\n",
       "  1141                                                   \n",
       "  1142                                           \n",
       "  1143                                                   # first we buffer it:        \n",
       "  1144       490       1022.0      2.1      0.6          if not self.gotfirstdata:\n",
       "  1145         1          2.0      2.0      0.0              self.gotfirstdata=True\n",
       "  1146         1          2.0      2.0      0.0              self.buff=data\n",
       "  1147                                                       \n",
       "  1148                                                       # what is the empty data look like?\n",
       "  1149         1          3.0      3.0      0.0              dimx, dimy = data.shape\n",
       "  1150                                                       \n",
       "  1151         1          8.0      8.0      0.0              self.empty_data = np.empty((0, dimy))\n",
       "  1152                                                       \n",
       "  1153                                                   else:\n",
       "  1154       489      36444.0     74.5     22.0              self.buff=np.concatenate((self.buff, data))\n",
       "  1155                                           \n",
       "  1156                                           \n",
       "  1157       490       2162.0      4.4      1.3          data_i = self.buff.shape[0]        \n",
       "  1158       490       5062.0     10.3      3.1          max_i = int(data_i // self.frac_downsample)\n",
       "  1159                                                   # then - we get the stuff we need:\n",
       "  1160                                                   \n",
       "  1161       490        676.0      1.4      0.4          if max_i > 0:\n",
       "  1162       490      39809.0     81.2     24.1              indices = [int(x * self.frac_downsample) for x in range(max_i)]\n",
       "  1163                                                       \n",
       "  1164                                                       \n",
       "  1165       490      39587.0     80.8     23.9              to_return = self.buff[indices,:]\n",
       "  1166                                                       \n",
       "  1167       490      34406.0     70.2     20.8              to_keep = self.buff[range(indices[-1]+round(self.frac_downsample),data_i),:]\n",
       "  1168                                                       \n",
       "  1169       490       1947.0      4.0      1.2              self.buff = to_keep\n",
       "  1170                                                       \n",
       "  1171                                                   else:\n",
       "  1172                                                       to_return = self.empty_data\n",
       "  1173                                                   \n",
       "  1174       490       4336.0      8.8      2.6          return self.rtfilter.handle(to_return)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -s -m rtfilters runLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amplifier stopped!\n"
     ]
    }
   ],
   "source": [
    "amp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05161199,  0.16482881, -0.0890512 , ..., -0.00238527,\n",
       "       -0.02011766,  0.3785572 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cwl._beta_shared_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "Q=multiprocessing.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nowait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.conda/envs/rt/lib/python3.6/multiprocessing/queues.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q.get_nowait?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\u001b[0m(1038)\u001b[0;36mhandle\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1037 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1038 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1039 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.buff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([], shape=(0, 38), dtype=float64)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 659.41060199,  658.6991346 ,  659.25327234, ...,  647.66778474,\n",
      "         631.96821966,  632.31727003],\n",
      "       [ 659.04145416,  658.08179843,  658.75489601, ...,  647.60889236,\n",
      "         631.64102415,  631.84603206],\n",
      "       [ 658.57498932,  657.59001058,  658.21078241, ...,  647.4740846 ,\n",
      "         631.42746428,  631.37870809],\n",
      "       ...,\n",
      "       [-197.38515447, -181.40978434, -188.47218639, ..., -181.74570221,\n",
      "        -175.81218772, -173.18305106],\n",
      "       [-197.74442442, -181.68199867, -188.17221261, ..., -181.88669696,\n",
      "        -175.62863734, -173.44709353],\n",
      "       [-198.13175727, -182.12629108, -187.84575362, ..., -182.01466308,\n",
      "        -175.43989604, -173.81104621]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1680, 38)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.concatenate(self.buff, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TypeError: only integer scalar arrays can be converted to a scalar index\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.concatenate(self.buff, self.buff)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TypeError: only integer scalar arrays can be converted to a scalar index\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.concatenate(data, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TypeError: only integer scalar arrays can be converted to a scalar index\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1680, 38)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 659.41060199,  658.6991346 ,  659.25327234, ...,  647.66778474,\n",
      "         631.96821966,  632.31727003],\n",
      "       [ 659.04145416,  658.08179843,  658.75489601, ...,  647.60889236,\n",
      "         631.64102415,  631.84603206],\n",
      "       [ 658.57498932,  657.59001058,  658.21078241, ...,  647.4740846 ,\n",
      "         631.42746428,  631.37870809],\n",
      "       ...,\n",
      "       [-197.38515447, -181.40978434, -188.47218639, ..., -181.74570221,\n",
      "        -175.81218772, -173.18305106],\n",
      "       [-197.74442442, -181.68199867, -188.17221261, ..., -181.88669696,\n",
      "        -175.62863734, -173.44709353],\n",
      "       [-198.13175727, -182.12629108, -187.84575362, ..., -182.01466308,\n",
      "        -175.43989604, -173.81104621]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.buff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([], shape=(0, 38), dtype=float64)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1680, 38)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1680, 38)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.buff.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 38)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  whos?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  whos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'whos' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data.shape[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data.shape[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'numpy' from '/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/__init__.py'>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.concatenate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import ipdb\n",
    "ipdb.post_mortem(sys.last_traceback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making movie animation.mpg - this may take a while\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "print('Making movie animation.mpg - this may take a while')\n",
    "subprocess.call(\"mencoder 'mf://_tmp*.png' -mf type=png:fps=10 -ovc lavc \"\n",
    "                \"-lavcopts vcodec=wmv2 -oac copy -o animation.mpg\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bla(var1, var2):\n",
    "    print(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bla2():\n",
    "    def __init__(self, var1):\n",
    "        self.var1=var1\n",
    "        \n",
    "    def print(self):\n",
    "        print(self.var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "CPU times: user 341 µs, sys: 0 ns, total: 341 µs\n",
      "Wall time: 344 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(1)\n",
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "b=bla2('1')\n",
    "b.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.001226 s\n",
       "File: <ipython-input-22-c5111973fb79>\n",
       "Function: print at line 5\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     5                                               def print(self):\n",
       "     6         1       1226.0   1226.0    100.0          print(self.var1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = %lprun -r -f b.print b.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<line_profiler.LineProfiler at 0x7f7228965468>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_line_profiler.LineStats at 0x7f7228963160>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/johan/.conda/envs/rt/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=np.random.random((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random((3,3)).copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f85cdf79080>,\n",
       " <matplotlib.lines.Line2D at 0x7f85cdf79c88>,\n",
       " <matplotlib.lines.Line2D at 0x7f85cdf79dd8>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(cwl.betas[-1][::4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/johan/nf/nf-rtime/Projects_Templates/3_RTMRICWL/rtfilters.py\u001b[0m(758)\u001b[0;36m_check_switch_betas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    757 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_incoming_betas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 758 \u001b[0;31m            \u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_incoming_betas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    759 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self._queue_incoming_betas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<multiprocessing.queues.Queue object at 0x7f6da80d8668>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self._queue_incoming_betas.qsize()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  a, b, c = self._queue_incoming_betas.get()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self = <rtfilters.CWL object at 0x7f6da80d8630>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self = <rtfilters.CWL object at 0x7f6da80d8630>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b\n",
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "import ipdb\n",
    "ipdb.post_mortem(sys.last_traceback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-c913c1dffb59>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-c913c1dffb59>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1+\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.000307 s\n",
       "File: <ipython-input-16-1dd24238f230>\n",
       "Function: bla at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def bla(var1, var2):\n",
       "     2         1        307.0    307.0    100.0      print(var1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f bla bla(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    %rerun 57\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Executing: ===\n",
      "%lprun -f bla bla(1,2)\n",
      "=== Output: ===\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0 s\n",
       "File: <ipython-input-16-1dd24238f230>\n",
       "Function: bla at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def bla(var1, var2):\n",
       "     2                                               print(var1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(): \n",
    "    %rerun 57\n",
    "%lprun -f bla f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f14eb4371b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_mortem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tb' is not defined"
     ]
    }
   ],
   "source": [
    "import pdb; pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu=[15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([4 > i for i in [0, 1, 2, 3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu[1:1+3]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark=[i for i, lastused in enumerate(lu) if lastused > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type help() for interactive help, or help(object) for help about object."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for popi in reversed(mark):\n",
    "    lu.pop(popi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=[-0.009725803730136564, -0.013286856216523535, -0.0015234020565639168, 0.007469876784025759, 0.21877457609218673, 0.060098715105399894, -0.01152044543151802, -0.010705063562098325, 0.06596197714099682, 0.2209395760192517, 0.03471496614715212, -0.010944518706039706, 0.1077332572705931, 0.9385757350172169, 0.10389958737708403, -0.010958975008754477, 0.034747485560958864, 0.2137010394744165, 0.058628170832456, -0.00995803061856474, -0.009521755934525783, 0.06403311973637298, 0.21299163216259706, 0.0334891349327988, -0.010564141057113813, 0.10636356482254435, 0.9339726306369603, 0.10463196522428422, -0.01063869291601751, 0.03586258392270768, 0.22050137141841994, 0.05935932319157627, -0.010372115253860061, -0.008732075113004207, 0.06545691207213597, 0.2204034773349035, 0.03627234910415857, -0.010316740351968527, 0.11455022632253853]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(l2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "print([1,2,3][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[].reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "mark=[]\n",
    "print(mark)\n",
    "print(mark.reverse())\n",
    "for popi in mark: #.reverse():\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-25. , -29. ,   4.5, ..., 104.5,  63. ,  51.5],\n",
       "       [-24.5, -30. ,   4. , ..., 104.5,  62. ,  50.5],\n",
       "       [-24.5, -29.5,   4. , ..., 104. ,  62. ,  51. ],\n",
       "       ...,\n",
       "       [  1.5,  44. , -29. , ..., -35. ,  48.5,  52.5],\n",
       "       [  2.5,  43.5, -28.5, ..., -34.5,  49. ,  52.5],\n",
       "       [  3. ,  42.5, -27.5, ..., -34. ,  48.5,  52. ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark=[x for x in []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mark:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10000-9900 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amplifier stopped!\n"
     ]
    }
   ],
   "source": [
    "amp.stop()\n",
    "alld.shrink_to_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x7f4754b4edd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5b0c1b52aa76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "a, b, c = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to disk, so we can re-load it later:\n",
    "\n",
    "t={'alld':alld, 'allm':allm, 'ch_names':ch_names, 'sfreq':sfreq}\n",
    "with open('c-allm-and-alld.pkl', 'wb') as f:\n",
    "    pickle.dump(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk:\n",
    "\n",
    "with open('c-allm-and-alld.pkl','rb') as f:\n",
    "    t=pickle.load(f)\n",
    "for key in t.keys():\n",
    "    locals()[key] = t[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../nftools/nftools/analysis.py:31: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n",
      "  montage=montage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=38, n_times=400001\n",
      "    Range : 0 ... 400000 =      0.000 ...    80.000 secs\n",
      "Ready.\n",
      "5000.0\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=400001\n",
      "    Range : 0 ... 400000 =      0.000 ...    80.000 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "raw = convert_alld_allm_to_mne(alld, allm, ch_names, sfreq)  # covert to MNE\n",
    "# raw.resample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(scalings='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw.set_eeg_reference(ref_channels='average')\n",
    "# better not (yet) - before removing bad channels, since these mess up your data big time: see PREP paper:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter\n",
      "Filter length of 33001 samples (6.600 sec) selected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawArray  |  None, n_channels x n_times : 39 x 400001 (80.0 sec), ~119.1 MB, data loaded>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False,\n",
    "                       stim=False, exclude='bads')\n",
    "\n",
    "raw.notch_filter(np.arange(50, 300, 50), picks=picks, filter_length='auto', phase='zero')\n",
    "# add it (potentialy) some other preprocessing steps here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.638 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims, initial)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/mne/viz/evoked.py:162: RuntimeWarning: invalid value encountered in maximum\n",
      "  rgb /= np.maximum(rgb.max(0), 1e-16)  # avoid div by zero\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/matplotlib/colors.py:251: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any((result < 0) | (result > 1)):\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/matplotlib/colors.py:251: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any((result < 0) | (result > 1)):\n"
     ]
    }
   ],
   "source": [
    "raw.plot_psd(tmax=np.inf, fmax=1000, n_fft=2048*4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "mne.viz.plot_sensors(raw.info, show_names=True, ch_type='eeg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loc': array([-0.0502438,  0.0531112,  0.042192 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'F3',\n",
       "  'scanno': 1,\n",
       "  'logno': 1},\n",
       " {'loc': array([0.0518362, 0.0543048, 0.040814 , 0.       , 0.       , 0.       ,\n",
       "         0.       , 0.       , 0.       , 0.       , 0.       , 0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'F4',\n",
       "  'scanno': 2,\n",
       "  'logno': 2},\n",
       " {'loc': array([-0.0653581, -0.0116317,  0.064358 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'C3',\n",
       "  'scanno': 3,\n",
       "  'logno': 3},\n",
       " {'loc': array([ 0.0671179, -0.0109003,  0.06358  ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'C4',\n",
       "  'scanno': 4,\n",
       "  'logno': 4},\n",
       " {'loc': array([-0.0530073, -0.0787878,  0.05594  ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'P3',\n",
       "  'scanno': 5,\n",
       "  'logno': 5},\n",
       " {'loc': array([ 0.0556667, -0.0785602,  0.056561 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'P4',\n",
       "  'scanno': 6,\n",
       "  'logno': 6},\n",
       " {'loc': array([-0.0365114, -0.1008529,  0.037167 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'PO3',\n",
       "  'scanno': 7,\n",
       "  'logno': 7},\n",
       " {'loc': array([ 0.0367816, -0.1008491,  0.036397 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'PO4',\n",
       "  'scanno': 8,\n",
       "  'logno': 8},\n",
       " {'loc': array([-0.0772149,  0.0186433,  0.02446  ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'FC5',\n",
       "  'scanno': 9,\n",
       "  'logno': 9},\n",
       " {'loc': array([0.0795341, 0.0199357, 0.024438 , 0.       , 0.       , 0.       ,\n",
       "         0.       , 0.       , 0.       , 0.       , 0.       , 0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'FC6',\n",
       "  'scanno': 10,\n",
       "  'logno': 10},\n",
       " {'loc': array([-0.0795922, -0.0465507,  0.030949 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'CP5',\n",
       "  'scanno': 11,\n",
       "  'logno': 11},\n",
       " {'loc': array([ 0.0833218, -0.0461013,  0.031206 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'CP6',\n",
       "  'scanno': 12,\n",
       "  'logno': 12},\n",
       " {'loc': array([-0.0702629,  0.0424743, -0.01142  ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'F7',\n",
       "  'scanno': 13,\n",
       "  'logno': 13},\n",
       " {'loc': array([ 0.0730431,  0.0444217, -0.012    ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'F8',\n",
       "  'scanno': 14,\n",
       "  'logno': 14},\n",
       " {'loc': array([-0.0841611, -0.0160187, -0.009346 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'T7',\n",
       "  'scanno': 15,\n",
       "  'logno': 15},\n",
       " {'loc': array([ 0.0850799, -0.0150203, -0.00949  ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'T8',\n",
       "  'scanno': 16,\n",
       "  'logno': 16},\n",
       " {'loc': array([-0.0724343, -0.0734527, -0.002487 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'P7',\n",
       "  'scanno': 17,\n",
       "  'logno': 17},\n",
       " {'loc': array([ 0.0730557, -0.0730683, -0.00254  ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'P8',\n",
       "  'scanno': 18,\n",
       "  'logno': 18},\n",
       " {'loc': array([-0.0856192, -0.0465147, -0.045707 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'TP9',\n",
       "  'scanno': 19,\n",
       "  'logno': 19},\n",
       " {'loc': array([ 0.0861618, -0.0470353, -0.045869 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'TP10',\n",
       "  'scanno': 20,\n",
       "  'logno': 20},\n",
       " {'loc': array([-0.0549104, -0.0980448, -0.035465 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'PO9',\n",
       "  'scanno': 21,\n",
       "  'logno': 21},\n",
       " {'loc': array([ 0.0549876, -0.0980911, -0.035541 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'PO10',\n",
       "  'scanno': 22,\n",
       "  'logno': 22},\n",
       " {'loc': array([ 0.0001123,  0.088247 , -0.001713 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'Fpz',\n",
       "  'scanno': 23,\n",
       "  'logno': 23},\n",
       " {'loc': array([0.0003122, 0.058512 , 0.066462 , 0.       , 0.       , 0.       ,\n",
       "         0.       , 0.       , 0.       , 0.       , 0.       , 0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'Fz',\n",
       "  'scanno': 24,\n",
       "  'logno': 24},\n",
       " {'loc': array([ 0.0004009, -0.009167 ,  0.100244 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'Cz',\n",
       "  'scanno': 25,\n",
       "  'logno': 25},\n",
       " {'loc': array([ 0.0003247, -0.081115 ,  0.082615 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'Pz',\n",
       "  'scanno': 26,\n",
       "  'logno': 26},\n",
       " {'loc': array([ 0.0002156, -0.102178 ,  0.050608 ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          0.       ,  0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'POz',\n",
       "  'scanno': 27,\n",
       "  'logno': 27},\n",
       " {'loc': array([ 1.07600e-04, -1.14892e-01,  1.46570e-02,  0.00000e+00,\n",
       "          0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00,\n",
       "          0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'Oz',\n",
       "  'scanno': 28,\n",
       "  'logno': 28},\n",
       " {'loc': array([ 4.50000e-06, -1.18565e-01, -2.30780e-02,  0.00000e+00,\n",
       "          0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00,\n",
       "          0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'Iz',\n",
       "  'scanno': 29,\n",
       "  'logno': 29},\n",
       " {'loc': array([0.0002313, 0.080771 , 0.035417 , 0.       , 0.       , 0.       ,\n",
       "         0.       , 0.       , 0.       , 0.       , 0.       , 0.       ]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'AFz',\n",
       "  'scanno': 30,\n",
       "  'logno': 30},\n",
       " {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'EOG',\n",
       "  'scanno': 31,\n",
       "  'logno': 31},\n",
       " {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'ECG',\n",
       "  'scanno': 32,\n",
       "  'logno': 32},\n",
       " {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'CW1',\n",
       "  'scanno': 33,\n",
       "  'logno': 33},\n",
       " {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'CW2',\n",
       "  'scanno': 34,\n",
       "  'logno': 34},\n",
       " {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'CW3',\n",
       "  'scanno': 35,\n",
       "  'logno': 35},\n",
       " {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'CW4',\n",
       "  'scanno': 36,\n",
       "  'logno': 36},\n",
       " {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'CW5',\n",
       "  'scanno': 37,\n",
       "  'logno': 37},\n",
       " {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       "  'unit_mul': 0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 2,\n",
       "  'coil_type': 1,\n",
       "  'unit': 107,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'CW6',\n",
       "  'scanno': 38,\n",
       "  'logno': 38},\n",
       " {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       "  'unit_mul': 0.0,\n",
       "  'range': 1.0,\n",
       "  'cal': 1.0,\n",
       "  'kind': 3,\n",
       "  'coil_type': 0,\n",
       "  'unit': -1,\n",
       "  'coord_frame': 0,\n",
       "  'ch_name': 'STI 014',\n",
       "  'scanno': 64,\n",
       "  'logno': 64}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['chs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_sensors?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
